<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Linguistic LOD &amp; Ontologies</title>
<meta name="author" content="(Vladimir Alexiev, Ontotext Corp)"/>
<link rel="stylesheet" href="http://cdn.jsdelivr.net/reveal.js/2.6.2/css/reveal.min.css"/>
<link rel="stylesheet" href="http://cdn.jsdelivr.net/reveal.js/2.6.2/css/theme/default.css" id="theme"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'http://cdn.jsdelivr.net/reveal.js/2.6.2/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<style>th, td {border: 1px; border-style: none solid; border-spacing:0; padding:0px 2px}</style>
<style>
.reveal .slides {text-align:left}
h1,h2,h3,h4,h5,h6,.center {text-align:center}
img {width:1200px}
.reveal th, .reveal td {border-width: 1px; border-style: none solid; border-spacing:0; padding:0px 2px}
span.clouditem {padding-left: 0.15em; padding-right: 0.15em; line-height: 90%}
</style>
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
<h1>Linguistic LOD &amp; Ontologies</h1>
<h2>Vladimir Alexiev, Ontotext Corp</h2>
<h2><a href="mailto:vladimir.alexiev@ontotext.com">vladimir.alexiev@ontotext.com</a></h2>
<h2>2014-06-03</h2>
<br/><br/><br/><br/><br/><br/>
<p class='center'>
Press <a href='javascript:Reveal.toggleOverview()'>O for overview</a>, <a href='reveal-help.html' target='_blank'>H for help</a>.</p>
<p class='center'>
Made with <a href='https://github.com/hakimel/reveal.js/'>reveal.js</a> and <a href='https://github.com/yjwen/org-reveal'>org-reveal</a>.</p></section>
<section>
<h2>Table of Contents</h2><ul>
<li>
<a href="#sec-1">Motivation</a>
<ul>
<li>
<a href="#sec-1-1">Artifacts</a>
</li>
<li>
<a href="#sec-1-2">Tag Cloud</a>
</li>
<li>
<a href="#sec-1-3">Zotero Bibliography</a>
</li>
<li>
<a href="#sec-1-4">Linguistic LOD</a>
</li>
</ul>
<li>
<a href="#sec-2">NLP Example</a>
</li>
<li>
<a href="#sec-3">Linguistic ontologies</a>
<ul>
<li>
<a href="#sec-3-1">NIF: Overall Idea</a>
</li>
<li>
<a href="#sec-3-2">NIF: Example (Merging Triples)</a>
</li>
<li>
<a href="#sec-3-3">NIF: Representation Profiles</a>
</li>
<li>
<a href="#sec-3-4">NIF: Domain Model</a>
</li>
<li>
<a href="#sec-3-5">OLIA and Constituents</a>
</li>
<li>
<a href="#sec-3-6">ITS2</a>
</li>
<li>
<a href="#sec-3-7">NERD</a>
</li>
<li>
<a href="#sec-3-8">FISE (Stanbol)</a>
</li>
<li>
<a href="#sec-3-9">MARL</a>
</li>
<li>
<a href="#sec-3-10">LEMON</a>
</li>
</ul>
<li>
<a href="#sec-4">Linguistic thesauri</a>
<ul>
<li>
<a href="#sec-4-1">ISOcat</a>
</li>
<li>
<a href="#sec-4-2">GOLD</a>
</li>
</ul>
<li>
<a href="#sec-5">Linguistic Linked Datasets</a>
<ul>
<li>
<a href="#sec-5-1">WordNet</a>
</li>
<li>
<a href="#sec-5-2">WordNet RDF</a>
</li>
<li>
<a href="#sec-5-3">Wiktionary</a>
</li>
<li>
<a href="#sec-5-4">BabelNet</a>
</li>
<li>
<a href="#sec-5-5">UBY-Lemon</a>
</li>
</ul>
</section>

<section>
<section id="sec-1" >

<h2>Motivation</h2>
<p>
There's been a flurry of activity in recent years to represent NLP data as RDF.
</p>
<ul class="org-ul">
<li><b>Covers</b>: Text Annotation (eg NIF, OLIA), Lexical Resources (eg WordNetRDF),
Corpora (eg MASC), Semantic Annotation, Opinion/Sentiment Analysis
</li>
<li><b>Working groups</b>: <a href="http://www.w3.org/community/ontolex">OntoLex</a> (W3C; Cimiano, Bielefeld), <a href="http://wiki.okfn.org/Working_Groups/Linguistics">OLWG</a> (OKFN; Chiarcos,
Frankfurt), <i>LD4LT</i> (W3C; Lewis, Trinity Dublin), BPMLOD (W3C; Gracia, UPM)
</li>
<li><b>Projects</b>: MultilingualWeb, <a href="http://lider-project.eu/">LIDER</a>, FALCON, BabelNet, etc, etc
</li>
</ul>
<p>
NLP data is usually large, why represent it in RDF?
</p>
<ul class="org-ul">
<li>Graph model is flexible and universal, appropriate for NLP
</li>
<li>RDF adds schemas and reasoning
</li>
<li>Large linguistic resources are available that may be used profitably
</li>
</ul>
</section>
<section id="sec-1-1" >

<h3>Artifacts</h3>
<ul class="org-ul">
<li><b>XML schemas</b>: GRaF, ITS2, LAF, LMF (ISO standards), UBY
</li>
<li><b>Ontologies</b>: FISE, ITS2 (W3C standard), LEMON, LIME, MARL, NERD, NIF (NLP2RDF),
OLIA, OntoLing, OntoTag, Penn, Stanford
</li>
<li><b>Linguistic thesauri</b>: GOLD, ISOcat, NERD
</li>
<li><b>Lexical resources</b>: BabelNet, FrameNet, LemonUBY, OmegaNet, VerbNet,
Wiktionary2RDF, WordNetRDF
</li>
<li><b>Corpora</b>: Multitext, MASC?
</li>
</ul>
</section>
<section id="sec-1-2"  tagcloud>

<h3>Tag Cloud</h3>
Text Annotation
Lexical Resources
Corpora
Semantic Annotation
Opinion/Sentiment Analysis
Working Groups:
OntoLex
LD4LT
BPMLOD
Projects: 
MultilingualWeb
LIDER
FALCON
XML schemas:
GRaF
ITS2
LAF
LMF
UBY
Ontologies:
FISE
ITS2
LEMON
LIME
MARL
NERD
NIF
NLP2RDF
OLIA
OntoLing
OntoTag
Penn
Stanford
Linguistic thesauri:
GOLD
ISOcat
NERD
Lexical resources:
BabelNet
FrameNet
LemonUBY
OmegaNet
VerbNet
Wiktionary2RDF
WordNetRDF
Corpora:
Multitext
MASC
</section>
<section id="sec-1-3" >

<h3>Zotero Bibliography</h3>
<p>
Collaborative bibliography on Linguistic LOD: representing language
resources and text annotations as RDF.
</p>
<ul class="org-ul">
<li><a href="https://www.zotero.org/groups/linguistic_ld">Zotero Group</a>: join so you can collaborate
</li>
<li><a href="https://www.zotero.org/groups/linguistic_ld/items">Zotero Library</a>: accessible on the web
</li>
</ul>
<img src="./img/zotero-web.png" alt="zotero-web.png" />
<ul class="org-ul">
<li>Intro: Christian Chiarcos, John McCrae, Philipp Cimiano, and Christiane
Fellbaum. <a href="http://www.lemon-model.net/papers/open-data-for-linguistics.pdf">Towards Open Data for Linguistics: Linguistic Linked Data</a>. In New
Trends of Research in Ontologies and Lexical Resources. Theory and Applications
of Natural Language Processing. Springer Berlin Heidelberg, 2013.
</li>
</ul>
</section>
<section id="sec-1-3-1" >

<h4>Zotero Collaboration</h4>
<ul class="org-ul">
<li>Install Zotero (FireFox plugin, or Zotero Standalone+Chrome), see below
</li>
<li>Collaborative tags (must add for each resource):
<ul class="org-ul">
<li>The topics above; add new topics freely
</li>
<li>HasRead: someone's read it, please add some Notes
</li>
<li>MustRead: likely to be used in Multisensor
</li>
</ul>
</li>
<li>If possible, add abstract, URL, the article itself.
</li>
</ul>
<img src="./img/zotero-standalone.png" alt="zotero-standalone.png" />
</section>
<section id="sec-1-4" >

<h3>Linguistic LOD</h3>
<img src="./img/llod-for-multisensor.png" alt="llod-for-multisensor.png" />
</section>
</section>
<section>
<section id="sec-2" >

<h2>NLP Example</h2>
<p>
Detailed example of annotating one sentence
</p>
<ul class="org-ul">
<li>Integrates knowledge about many of the ontologies described here
</li>
<li><a href="http://vladimiralexiev.github.io/Multisensor/NIF-example.ttl">http://vladimiralexiev.github.io/Multisensor/NIF-example.ttl</a>
</li>
</ul>
<p>
Areas covered include:
</p>
<ul class="org-ul">
<li>Binding to text (NIF)
</li>
<li>Lemma/stem (NIF)
</li>
<li>POS tagging (Penn)
</li>
<li>Dependency parsing (Stanford)
</li>
<li>Semantic annotation classes (NERD, ITS2)
</li>
<li>Semantic annotation individuals (DBpedia, WordNet, ITS2)
</li>
<li>Multiple semantic annotations (FISE/Stanbol)
</li>
<li>Opinion/sentiment (MARL)
</li>
</ul>
</section>
</section>
<section>
<section id="sec-3" >

<h2>Linguistic ontologies</h2>
<p>
We describe briefly the following linguistic ontologies
</p>
<ul class="org-ul">
<li>NIF (NLP2RDF): bind nodes to text, basic NLP properties
</li>
<li>OLIA: tagsets, morphological/syntactic/parsing representations
</li>
<li>Some OLIA constituents: Penn, Stanford
</li>
<li>ITS2: semantic annotation properties
</li>
<li>NERD: Semantic annotation classes
</li>
<li>FISE (Stanbol): multiple semantic annotations
</li>
<li>MARL: Opinion/sentiment
</li>
<li>LEMON, LIME (?TODO): lexicographic info (dictionaries)
</li>
</ul>
</section>
<section id="sec-3-1" >

<h3>NIF: Overall Idea</h3>
<img src="./img/NIF-idea.png" alt="NIF-idea.png" />
</section>
<section id="sec-3-2" >

<h3>NIF: Example (Merging Triples)</h3>
<img src="./img/NIF-example-favourite-actress.png" alt="NIF-example-favourite-actress.png" />
</section>
<section id="sec-3-3" >

<h3>NIF: Representation Profiles</h3>
<img src="./img/NIF-profiles.png" alt="NIF-profiles.png" />
</section>
<section id="sec-3-4" >

<h3>NIF: Domain Model</h3>
<img src="./img/NIF-schema.png" alt="NIF-schema.png" />
</section>
<section id="sec-3-5" >

<h3>OLIA and Constituents</h3>
</section>
<section id="sec-3-5-1" >

<h4>Penn</h4>
</section>
<section id="sec-3-5-2" >

<h4>Stanford</h4>
</section>
<section id="sec-3-6" >

<h3>ITS2</h3>
</section>
<section id="sec-3-7" >

<h3>NERD</h3>
</section>
<section id="sec-3-8" >

<h3>FISE (Stanbol)</h3>
</section>
<section id="sec-3-9" >

<h3>MARL</h3>
</section>
<section id="sec-3-10" >

<h3>LEMON</h3>
</section>
</section>
<section>
<section id="sec-4" >

<h2>Linguistic thesauri</h2>
</section>
<section id="sec-4-1" >

<h3>ISOcat</h3>
</section>
<section id="sec-4-2" >

<h3>GOLD</h3>
</section>
</section>
<section>
<section id="sec-5" >

<h2>Linguistic Linked Datasets</h2>
<p>
In the following slides I describe large-scale Linguistic resources.<br  />
Datasets already integrated in FactForge:
</p>
<ul class="org-ul">
<li>WordNet (includes the W3C RDF representation of WordNet 3.1)
</li>
<li>Lingvoj, Lexvo: info about languages
</li>
</ul>
</section>
<section id="sec-5-1" >

<h3>WordNet</h3>
<p>
<a href="http://wordnet.princeton.edu/">WordNet</a>: well-known and prototypical lexical resource
</p>
<ul class="org-ul">
<li>117k synsets, glosses, numerous synonyms (words/phrases).
</li>
<li>Hyponyms/hyperonyms, meronyms, antonyms
</li>
<li>Uses its own properties
</li>
<li>Ontology developed by W3C in 2005
</li>
</ul>
</section>
<section id="sec-5-1-1" >

<h4>ImageNet</h4>
<p>
<a href="http://www.image-net.org">./img/imagenet.jpg</a> includes sample images for WordNet
</p>
<ul class="org-ul">
<li>5k images per noun synset!
</li>
<li>enables automatic image annotation
</li>
<li>human-curated bounding boxes, eg "fox" and "airplane"
</li>
</ul>
<p>
<img src="./img/imagenet-bbox-fox.jpg" alt="imagenet-bbox-fox.jpg" /><img src="./img/imagenet-bbox-airplane.jpg" alt="imagenet-bbox-airplane.jpg" />
</p>
</section>
<section id="sec-5-2" >

<h3>WordNet RDF</h3>
</section>
<section id="sec-5-3" >

<h3>Wiktionary</h3>
</section>
<section id="sec-5-4" >

<h3>BabelNet</h3>
<ul class="org-ul">
<li>50 languages covered
</li>
<li>Integrates WordNet, Open Multilingual WordNet, Wikipedia, OmegaWiki, Wikidata, Wiktionary
</li>
<li>Useful for multilingual joint Word Sense Disambiguation
</li>
<li>9.3M synsets, 67M senses
</li>
<li>21.7M textual definitions
</li>
<li>262M semantic relations
</li>
<li>7.7M synset-associated images
</li>
<li>1.1 billion triples in RDF/Lemon, available for download, public SPARQL endpoint
</li>
<li>Java APIs for programmatic access
</li>
</ul>
</section>
<section id="sec-5-4-1" >

<h4>Babelfy</h4>
<p>
<a href="http://babelfy.org/index.jsp">Babelfy</a>: annotation API based on BabelNet (just released)
</p>
<ul class="org-ul">
<li>Evaluation on Energy news item (green: ok concepts, yellow: ok entities, orange: missed/irrelevant, red: wrong)
</li>
</ul>
<img src="./img/babelfy.png" alt="babelfy.png" />
</section>
<section id="sec-5-5" >

<h3>UBY-Lemon</h3>
<p>
<a href="http://lemon-model.net/lexica/uby/">./img/uby-lemon.png</a><br  />
Integrates in LEMON format:
</p>
<ul class="org-ul">
<li>FrameNet
</li>
<li>OmegaWiki (English, German)
</li>
<li>VerbNet
</li>
<li>Wiktionary (English, German)
</li>
<li>Princeton WordNet 3.0
</li>
</ul>
</section>
</section>
</div>
</div>
<script>
Reveal.configure ({mouseWheel:true, previewLinks:true, viewDistance:4,
  keyboard:{
    72:function(){ // H=toggle history
      // var r = Reveal.getIndices();
      Reveal.configure({history:!window.location.hash}); 
      if (!!window.location.hash) {window.location.hash=''}; 
      window.location.reload;
      // Reveal.slide(r.h,r.v)
      // unfortunately goes to first slide when history is turned off, last line doesn't fix
      // https://github.com/hakimel/reveal.js/issues/934
    },
    63:function(){ // ?=keyboard help
      window.open('reveal-help.html#/1','_blank','width=720,height=540,location=0,menubar=0,scrollbars=0,status=0,titlebar=0,toolbar=0');
    }}})
</script>
<script src="http://cdn.jsdelivr.net/reveal.js/2.6.2/lib/js/head.min.js"></script>
<script src="http://cdn.jsdelivr.net/reveal.js/2.6.2/js/reveal.min.js"></script>
<script>

        		// Full list of configuration options available here:
        		// https://github.com/hakimel/reveal.js#configuration
        		Reveal.initialize({
        			controls: true,
        			progress: true,
        			history: false,
        			center: true,
                                slideNumber: true,
        			rollingLinks: false,
        			keyboard: true,
        			overview: true,
        			width: 1200, // slide width
        			height: 900, // slide height
        			 // slide margin
        			 // slide minimum scaling factor
        			 // slide maximum scaling factor


        			theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
        			transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none
        			transitionSpeed: 'default',

        			// Optional libraries used to extend on reveal.js
        			dependencies: [
        				{ src: 'http://cdn.jsdelivr.net/reveal.js/2.6.2/lib/js/classList.js', condition: function() { return !document.body.classList; } }
        				//,{ src: 'http://cdn.jsdelivr.net/reveal.js/2.6.2/plugin/markdown/showdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } }
        				//,{ src: 'http://cdn.jsdelivr.net/reveal.js/2.6.2/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } }
        				,{ src: 'http://cdn.jsdelivr.net/reveal.js/2.6.2/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
        				,{ src: 'http://cdn.jsdelivr.net/reveal.js/2.6.2/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } }
        				,{ src: 'http://cdn.jsdelivr.net/reveal.js/2.6.2/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
        				//,{ src: 'http://cdn.jsdelivr.net/reveal.js/2.6.2/plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
        				//,{ src: 'http://cdn.jsdelivr.net/reveal.js/2.6.2/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
         				,{src: 'js/reveal-help.js', async: true, condition: function() {return !!document.body.classList}}, {src: 'js/reveal-tagcloud.js', async: true, condition: function() {return !!document.body.classList}}
        			]
        		});
</script>
</body>
</html>
