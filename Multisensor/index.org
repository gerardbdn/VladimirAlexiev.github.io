#+TITLE: Multisensor RDF Application Profile
#+DATE: <2016-07-01>
#+AUTHOR: Vladimir Alexiev
#+EMAIL: vladimir.alexiev@ontotext.com
#+OPTIONS: ':nil *:t -:t ::t <:t H:5 \n:nil ^:{} arch:headline author:t c:nil
#+OPTIONS: creator:comment d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil stat:t tags:t tasks:t tex:t timestamp:t toc:t todo:nil |:t
#+CREATOR: Emacs 25.0.50.1 (Org mode 8.2.10)
#+DESCRIPTION:
#+EXCLUDE_TAGS: noexport
#+KEYWORDS:
#+LANGUAGE: en
#+SELECT_TAGS: export

[[http://VladimirAlexiev.github.io/Multisensor/index.html][HTML Rendered version]]

* Table of Contents                                 :TOC:
 - [[#intro][Intro]]
   - [[#linguistic-linked-data][Linguistic Linked Data]]
   - [[#nif-issues][NIF Issues]]
 - [[#prefixes][Prefixes]]
   - [[#multisensor-ontologies][Multisensor Ontologies]]
   - [[#multisensor-datasets][Multisensor Datasets]]
   - [[#external-datasets][External Datasets]]
   - [[#common-ontologies][Common Ontologies]]
   - [[#linguistic-and-annotation-ontologies][Linguistic and Annotation ontologies]]
   - [[#statistical-ontologies][Statistical Ontologies]]
   - [[#eurostat-statistical-parameters][Eurostat Statistical Parameters]]
   - [[#worldbank-statistical-parameters][WorldBank Statistical Parameters]]
   - [[#auxiliary-prefixes][Auxiliary Prefixes]]
   - [[#jsonld-context][JSONLD Context]]
 - [[#nif-example][NIF Example]]
   - [[#example-context][Example Context]]
   - [[#string-position-urls][String Position URLs]]
   - [[#position-urls-to-word-urls][Position URLs to Word URLs]]
   - [[#basic-text-structure][Basic Text Structure]]
   - [[#part-of-speech][Part of Speech]]
   - [[#dependency-parse][Dependency Parse]]
   - [[#ner-classes][NER Classes]]
   - [[#ner-individuals][NER Individuals]]
   - [[#ner-provenance][NER Provenance]]
   - [[#sentiment-analysis-with-marl][Sentiment Analysis with MARL]]
   - [[#sentiment-analysis-in-nif][Sentiment Analysis in NIF]]
 - [[#rdf-validation][RDF Validation]]
   - [[#nif-validator][NIF Validator]]
   - [[#rdfunit-validation][RDFUnit Validation]]
     - [[#generated-tests-per-ontology][Generated Tests per Ontology]]
     - [[#rdfunit-test-results][RDFUnit Test Results]]
   - [[#manual-validation][Manual Validation]]
     - [[#get-turtle-from-store][Get Turtle from Store]]
     - [[#get-turtle-from-simmo-json][Get Turtle from SIMMO JSON]]
       - [[#prettify-turtle][Prettify Turtle]]
 - [[#graph-handling][Graph Handling]]
   - [[#storing-service-put-vs-post][Storing Service PUT vs POST]]
   - [[#graph-normalization][Graph Normalization]]
     - [[#query-changes][Query Changes]]
     - [[#normalization-problems][Normalization Problems]]
 - [[#simmo][SIMMO]]
 - [[#multisensor-named-entity-recognition][Multisensor Named Entity Recognition]]
   - [[#ner-mapping][NER Mapping]]
   - [[#example][Example]]
     - [[#named-entity-urls][Named Entity URLs]]
   - [[#todo][TODO]]
 - [[#relation-extraction][Relation Extraction]]
 - [[#confidence-and-provenance][Confidence and Provenance]]
   - [[#multiple-annotations-with-fise][Multiple Annotations with FISE]]
   - [[#multiple-annotations-with-nif-21-rc][Multiple Annotations with NIF 2.1 RC]]
   - [[#nif-21-rc-backward-incompatibility][NIF 2.1 RC Backward Incompatibility]]
   - [[#singling-out-an-annotation][Singling Out an Annotation]]
 - [[#babelnet-concepts][Babelnet Concepts]]
   - [[#generic-vs-specific-concepts][Generic vs Specific Concepts]]
 - [[#multimedia-annotation][Multimedia Annotation]]
   - [[#automatic-speech-recognition][Automatic Speech Recognition]]
     - [[#aside-isocat--gold][Aside: ISOcat & GOLD]]
   - [[#basic-image-annotation][Basic Image Annotation]]
     - [[#open-annotation][Open Annotation]]
     - [[#representing-confidence-with-stanbol-fise][Representing Confidence with Stanbol FISE]]
       - [[#removing-redundancy][Removing Redundancy]]
     - [[#representing-confidence-with-fam][Representing Confidence with FAM]]
     - [[#representing-confidence-with-reification][Representing Confidence with Reification]]
   - [[#annotating-images][Annotating Images]]
   - [[#annotating-videos][Annotating Videos]]
   - [[#annotating-video-frames][Annotating Video Frames]]
 - [[#translation][Translation]]
 - [[#multisensor-social-data][Multisensor Social Data]]
   - [[#topic-based-on-single-keywords][Topic Based on Single Keywords]]
   - [[#topic-based-on-multiple-hashtags][Topic Based on Multiple Hashtags]]
   - [[#tweets-related-to-article][Tweets Related to Article]]
 - [[#multisensor-sentiment-analysis][Multisensor Sentiment Analysis]]
   - [[#text-characteristics][Text Characteristics]]
   - [[#sentiment-of-simmo-and-sentence][Sentiment of SIMMO and Sentence]]
   - [[#sentiment-about-named-entity][Sentiment About Named Entity]]
 - [[#content-similarity][Content Similarity]]

* Intro
This document represents an "RDF Application Profile" for Multisensor, i.e. describes various RDF shapes used by Multisensor to store its data.
We cover the following areas:
- Linguistic Linked Data in NLP Interchange Format (NIF), including Part of Speech (POS), dependency parsing, sentiment, Named Entity Recognition (NER), etc
- Speech recognition, translation
- Multimedia binding and image annotation
- Statistical data
- Social network popularity and influence, etc

A few technical aspects (eg Graph Normalization) are also covered.
The companion document [[https://docs.google.com/document/d/1FfkiiTYvrLzHJ5P5j34NRVGPbXml0ndpNtiNbH2osRw/edit][Multisensor SPARQL Queries]] describes various queries used by the system.

The document is developed in Emacs Org-mode using a Literate Programming style.
Illustrative code and ontology fragments use RDF Turtle, and are assembled ("tangled") using Org Babel support to [[./img]].
Figures are made with the *rdfpuml* tool from actual Turtle, see:
- Making True RDF Diagrams with rdfpuml. Alexiev, V. March 2016. [[http://vladimiralexiev.github.io/pres/20160325-rdfpuml/index.html][interactive presentation]], [[http://vladimiralexiev.github.io/pres/20160325-rdfpuml/index-full.html][continuous HTML]]

Early presentation:
- [[./20140519-Multisensor-LD/Multisensor-LD.html][Multisensor Linked Data]]: web presentation 2014-05-19, Barcelona

** Linguistic Linked Data
There's been a huge drive in recent years to represent NLP data as RDF. NLP data is usually large, so does it make sense to represent it as RDF? What's the benefit?
- Ontologies, schemas and groups include: GRaF ITS2 FISE LAF LD4LT LEMON LIME LMF MARL NERD NIF NLP2RDF OLIA OntoLex OntoLing OntoTag Penn Stanford... my oh my!
- There are a lot of linguistic resources available that can be used profitably: BabelNet FrameNet GOLD ISOcat LemonUBY Multitext OmegaNet UBY VerbNet Wiktionary WordNet.
The benefit is that RDF offers a lot of flexibility for combining data on many different topics in one graph.

The NLP Interchange Format (NIF) is the pivot ontology that allows binding to text, and integrates many other aspects
- [[./20141008-Linguistic-LD/][Linguistic Linked Data]]:  presentation, 2014-10-08, Bonn, Germany. Covers NIF, POS (Penn), dependency parsing (Stanford), morphology (OLIA), sentiment (MARL), etc
- [[https://www.zotero.org/groups/linguistic_ld/items][Zotero Linguistic LD bibliography]]

** NIF Issues
As any new technology, NIF has various issues. A new version NIF 2.1 is in development and has raised its own issues.
Issues that I've posted about NIF:
- [[https://github.com/NLP2RDF/specification/issues/1][specification/issues/1]]: nif:opinion vs marl:extractedFrom. Example: [[./NIF-issue-1.ttl]]
- [[https://github.com/NLP2RDF/specification/issues/2][specification/issues/2]]: itsrdf vs fise properties. Example: [[./NIF-issue-2.ttl]]
- [[https://github.com/NLP2RDF/ontologies/issues/12][ontologies/issues/12]]: location of NIF3.0 and issue tracker
- [[https://github.com/NLP2RDF/ontologies/issues/19][ontologies/issues/19]] nif:AnnotationUnit vs nifs:Annotation vs fise:EntityAnnotation vs fam:EntityAnnotation
- [[https://github.com/NLP2RDF/ontologies/issues/18][ontologies/issues/18]] comment on itsrdf:taAnnotatorsRef
- [[https://github.com/NLP2RDF/ontologies/issues/17][ontologies/issues/17]] Are lots of sub-classes and sub-properties needed?
- [[https://github.com/NLP2RDF/ontologies/issues/16][ontologies/issues/16]] URL persistence vs modularisation
- [[https://github.com/NLP2RDF/ontologies/issues/8][ontologies/issues/8]] nif:lang has multiple domains
- [[https://github.com/NLP2RDF/documentation/issues/1][documentation/issues/1]]: who's developing NIF 2.1 and where? (Provenance and Confidence)

* Prefixes
Multisensor uses the following prefixes. 
We define the prefixes once, and then can use them in Turtle examples without redefining them, guaranteeting consistency.
When this file is loaded in GraphDB, we can also make queries without worrying about the prefixes.

[[./img/prefixes.ttl]]

A lot of the prefixes are registered in prefix.cc and can be obtained with a URL like:
- http://prefix.cc/dbr,dbo,dc,fise,itsrdf,nif,olia,owl,penn,sioc,stanford,xsd,yago.ttl

** Multisensor Ontologies
UPF has defined a number of subsidiary ontologies related to Dependency Parsing (~dep~) and FrameNet (~frame~ and ~fe~).
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# Multisensor ontologies
@prefix ms:             <http://data.multisensorproject.eu/ontology#> .
@prefix upf-deep:       <http://taln.upf.edu/upf-deep#> .
@prefix upf-dep-spa:    <http://taln.upf.edu/upf-dep-spa#> .
@prefix upf-dep-syn:    <http://taln.upf.edu/olia/penn-dep-syntax#> .
@prefix fe-upf:         <http://taln.upf.edu/frame-element#> . 
@prefix frame-upf:      <http://taln.upf.edu/frame#> .

#+END_SRC

The Multisensor ontology gathers various classes and properties. 
Here we define its metadata (header), while classes and properties are defined in later sections on as-needed basis.

[[./img/ontology.ttl]]
#+BEGIN_SRC Turtle :tangle ./img/ontology.ttl
ms: a owl:Ontology;
  rdfs:label "Multisensor Ontology";
  rdfs:comment "Defines various classes and properties used by the FP7 Multisensor project";
  rdfs:seeAlso <http://multisensorproject.eu>, <http://vladimiralexiev.github.io/Multisensor/>;
  dct:creator <http://multisensorproject.eu>, <mailto:vladimir.alexiev@ontotext.com>;
  dct:created  "2016-06-20"^^xsd:date.

#+END_SRC

** Multisensor Datasets
The main Multisensor dataset is ~ms-content~ which includes the annotated news content (SIMMOs).
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# Multisensor datasets
@prefix ms-annot:       <http://data.multisensorproject.eu/annot/>.
@prefix ms-content:     <http://data.multisensorproject.eu/content/>.
@prefix ms-concept:     <http://data.multisensorproject.eu/concept/>.
@prefix ms-soc:         <http://data.multisensorproject.eu/social/> .

#+END_SRC

** External Datasets
We use two well-known LOD datasets for NER references (Babelnet ~bn~ and DBpedia ~dbr~). Yago is used only in examples.
In addition, we make up a namespace for Twitter tags and users.
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# External datasets
@prefix bn:             <http://babelnet.org/rdf/> .
@prefix dbr:            <http://dbpedia.org/resource/> .
@prefix yago:           <http://yago-knowledge.org/resource/>.
@prefix twitter:        <http://twitter.com/>.
@prefix twitter_tag:    <http://twitter.com/hashtag/>.
@prefix twitter_user:   <http://twitter.com/intent/user?user_id=> .

#+END_SRC

** Common Ontologies
The following ontologies are commonly used
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# Commonly used ontologies
@prefix dbo:            <http://dbpedia.org/ontology/> .
@prefix dbp:            <http://dbpedia.org/property/> .
@prefix dc:             <http://purl.org/dc/elements/1.1/> .
@prefix dct:            <http://purl.org/dc/terms/> .
@prefix dctype:         <http://purl.org/dc/dcmitype/>.
@prefix foaf:           <http://xmlns.com/foaf/0.1/> .
@prefix schema:         <http://schema.org/> .
@prefix sioc:           <http://rdfs.org/sioc/ns#>.
@prefix skos:           <http://www.w3.org/2004/02/skos/core#>.

# System ontologies
@prefix rdf:            <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs:           <http://www.w3.org/2000/01/rdf-schema#> .
@prefix owl:            <http://www.w3.org/2002/07/owl#> .
@prefix xsd:            <http://www.w3.org/2001/XMLSchema#> .
#+END_SRC

** Linguistic and Annotation ontologies
These ontologies are the main "work-horse" in Multisensor, i.e. used to represent the majority of the data
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# Linguistic and Annotation ontologies
@prefix fam:            <http://vocab.fusepool.info/fam#>.
@prefix fise:           <http://fise.iks-project.eu/ontology/>.
@prefix its:            <http://www.w3.org/2005/11/its/rdf#> .
@prefix marl:           <http://purl.org/marl/ns#> .
@prefix nerd:           <http://nerd.eurecom.fr/ontology#> .
@prefix nif:            <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#> .
@prefix nif-ann:        <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-annotation#>.
@prefix oa:             <http://www.w3.org/ns/oa#>.
@prefix olia:           <http://purl.org/olia/olia.owl#> .
@prefix penn:           <http://purl.org/olia/penn.owl#> .
@prefix stanford:       <http://purl.org/olia/stanford.owl#>.

# FrameNet ontologies
@prefix fn:             <http://www.ontologydesignpatterns.org/ont/framenet/tbox/> .
@prefix frame:          <http://www.ontologydesignpatterns.org/ont/framenet/abox/frame/> .
@prefix fe:             <http://www.ontologydesignpatterns.org/ont/framenet/abox/fe/> .
@prefix lu:             <http://www.ontologydesignpatterns.org/ont/framenet/abox/lu/> .
@prefix st:             <http://www.ontologydesignpatterns.org/ont/framenet/abox/semType/> .

#+END_SRC

** Statistical Ontologies
Multisensor uses statistical ontologies for representing Decision Support data
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# Common statistical ontologies (CUBE, SDMX)
@prefix qb:             <http://purl.org/linked-data/cube#> .
@prefix sdmx-code:      <http://purl.org/linked-data/sdmx/2009/code#> .
@prefix sdmx-attribute: <http://purl.org/linked-data/sdmx/2009/attribute#> .
@prefix sdmx-dimension: <http://purl.org/linked-data/sdmx/2009/dimension#> .
@prefix sdmx-measure:   <http://purl.org/linked-data/sdmx/2009/measure#> .

#+END_SRC

** Eurostat Statistical Parameters
One of the main sources of statistical data is Eurostat. We also use some of their parameters (eg ~eugeo~) to represent our own stats datasets.
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# Eurostat statistics
@prefix eu:             <http://eurostat.linked-statistics.org/dic/>.
@prefix eu_age:         <http://eurostat.linked-statistics.org/dic/age#>.
@prefix eu_adj:         <http://eurostat.linked-statistics.org/dic/s_adj#>.
@prefix eu_flow:        <http://eurostat.linked-statistics.org/dic/stk_flow#>.
@prefix eu_partner:     <http://eurostat.linked-statistics.org/dic/partner#>.
@prefix eudata:         <http://eurostat.linked-statistics.org/data/> .
@prefix eugeo:          <http://eurostat.linked-statistics.org/dic/geo#>.
@prefix indic:          <http://eurostat.linked-statistics.org/dic/indic#>.
@prefix indic_bp:       <http://eurostat.linked-statistics.org/dic/indic_bp#>.
@prefix indic_et:       <http://eurostat.linked-statistics.org/dic/indic_et#>.
@prefix indic_is:       <http://eurostat.linked-statistics.org/dic/indic_is#>.
@prefix indic_na:       <http://eurostat.linked-statistics.org/dic/indic_na#>.
@prefix prop:           <http://eurostat.linked-statistics.org/property#> .
@prefix unit:           <http://eurostat.linked-statistics.org/dic/unit#> .

#+END_SRC

** WorldBank Statistical Parameters
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# WorldBank statistics
@prefix country:        <http://worldbank.270a.info/classification/country/> .
@prefix indicator:      <http://worldbank.270a.info/classification/indicator/> .
@prefix property:       <http://worldbank.270a.info/property/> .

#+END_SRC

** Auxiliary Prefixes
These prefixes are used for auxiliary purposes. 
Eg ~puml~ is used in example files to give *rdfpuml* instructions that improve diagram appearance
#+BEGIN_SRC Turtle :tangle ./img/prefixes.ttl
# Auxiliary prefixes
@prefix puml:           <http://plantuml.com/ontology#>.
@prefix prov:           <http://www.w3.org/ns/prov#>.
@prefix ex:             <http://example.org/>.
#+END_SRC

** JSONLD Context
Multisensor uses JSONLD for communication of RDF data between the various pipeline modules.
We can use a JSONLD Context from the prefixes to shorten the representation.
We make the context using the following command:
#+BEGIN_SRC sh
riot --formatted=jsonld prefixes.ttl > multisensor.jsonld
#+END_SRC

[[./img/multisensor.jsonld]]

* NIF Example
This first example shows NLP data in RDF Turtle. It covers:
- NIF (text binding)
- OLIA (linguistic properties)
- Penn (POS tagging)
- Stanford (dependency parsing)
- ITS20 (NER or semantic annotation)
- NERD (NER classes)
- Stanbol/FISE (multiple NLP tools/annotations per word/phrase)
- MARL (opinion/sentiment)
It uses NE (entities) from DBpedia, WordNet, YAGO

- [[./NIF-example.ttl]]
- [[./NIF-example.jsonld]]: same in JSONLD, shows that Turtle should be used for examples/discussion/QA and JSONLD for machine communication only

** Example Context
Assume that http://example.com/blog/1 is a blog post with the text "Germany is the work horse of the European Union".
First we represent the text as a whole.
~isString~ means this Context is considered *equivalent* to its string value.
~sourceUrl~ points to Where the text came from, same as the ~@base~
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
@base <http://example.com/blog/1/> .
<#char=0,47> a nif:Context; # the complete text
  nif:isString "Germany is the work horse of the European Union";
  nif:sourceUrl <>.
#+END_SRC

** String Position URLs
The recommended NIF URLs are position-based (following RFC 5147): ~<#char=x,y>~ .
The count is 0-based and spaces are counted as 1 (NIF 2.0 Core Spec, String Counting and Determination of Length).
Here are the positions of each word:
:  Germany is   the   work  horse of    the   European Union
:  0,7     8,10 11,14 15,19 20,25 26,28 29,32 33,41    42,47
All string URLs must refer to the context using ~referenceContext.
~beginIndex/endIndex~ are counted within the context's ~isString~.

We indicate the datatype of ~beginIndex/endIndex~ explicitly, as specified in NIF, and unlike examples which omit it.
Please note that in Turtle a number like 7 means ~xsd:integer~, not ~xsd:nonNegativeInteger~ (see [[http://www.w3.org/TR/turtle/#abbrev][Turtle spec]])

#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#char=0,7>   a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "0"^^xsd:nonNegativeInteger;  nif:endIndex "7"^^xsd:nonNegativeInteger.
<#char=8,10>  a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "8"^^xsd:nonNegativeInteger;  nif:endIndex "10"^^xsd:nonNegativeInteger.
<#char=11,14> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "11"^^xsd:nonNegativeInteger; nif:endIndex "14"^^xsd:nonNegativeInteger.
<#char=15,19> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "15"^^xsd:nonNegativeInteger; nif:endIndex "19"^^xsd:nonNegativeInteger.
<#char=20,25> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "20"^^xsd:nonNegativeInteger; nif:endIndex "25"^^xsd:nonNegativeInteger.
<#char=26,28> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "26"^^xsd:nonNegativeInteger; nif:endIndex "28"^^xsd:nonNegativeInteger.
<#char=29,32> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "29"^^xsd:nonNegativeInteger; nif:endIndex "32"^^xsd:nonNegativeInteger.
<#char=33,41> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "33"^^xsd:nonNegativeInteger; nif:endIndex "41"^^xsd:nonNegativeInteger.
<#char=42,47> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "42"^^xsd:nonNegativeInteger; nif:endIndex "47"^^xsd:nonNegativeInteger.
#+END_SRC

We also introduce URLs for a couple of phrases.
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#char=15,25> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "15"^^xsd:nonNegativeInteger; nif:endIndex "25"^^xsd:nonNegativeInteger.
<#char=33,47> a nif:RFC5147String; nif:referenceContext <#char=0,47>;
  nif:beginIndex "33"^^xsd:nonNegativeInteger; nif:endIndex "47"^^xsd:nonNegativeInteger.
#+END_SRC

** Position URLs to Word URLs
In this example we introduce word-based URLs, which make the following statements more clear
(especially for Stanford Dependency Parse).
owl:sameAs makes two resources equivalent, so all their statements are "smushed" between each other.
The URLs don't make any semantic difference, and in the actual implementation we use only position-based URLs.
We also introduce URLs for the text as a whole, and a couple of phrases.
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#char=0,47>  owl:sameAs <#ROOT-0>.
<#char=0,7>   owl:sameAs <#Germany-1>.
<#char=8,10>  owl:sameAs <#is-2>.
<#char=11,14> owl:sameAs <#the-3>.
<#char=15,19> owl:sameAs <#work-4>.
<#char=20,25> owl:sameAs <#horse-5>.
<#char=26,28> owl:sameAs <#of-6>.
<#char=29,32> owl:sameAs <#the-7>.
<#char=33,41> owl:sameAs <#European-8>.
<#char=42,47> owl:sameAs <#Union-9>.
<#char=15,25> owl:sameAs <#work-horse>.
<#char=33,47> owl:sameAs <#European-Union>.
#+END_SRC

** Basic Text Structure
NLP tools would usually record whether each URL is a Word, Phrase, Sentence...
URLs *may* state the corresponding word with ~nif:anchorOf~.
This is redundant, since it can be inferred from the context's ~isString~ and indexes, 
but is very useful for debugging, and Multisensor records it in production.

We can also record Lemma and  Stemming
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#ROOT-0> a nif:Sentence. # no nif:anchorOf because it already has the mandatory subprop nif:isString
<#Germany-1>      nif:anchorOf "Germany";        a nif:Word.
<#is-2>           nif:anchorOf "is";             a nif:Word.
<#the-3>          nif:anchorOf "the";            a nif:Word.
<#work-4>         nif:anchorOf "work";           a nif:Word.
<#horse-5>        nif:anchorOf "horse";          a nif:Word.
<#of-6>           nif:anchorOf "of";             a nif:Word.
<#the-7>          nif:anchorOf "the";            a nif:Word.
<#European-8>     nif:anchorOf "European";       a nif:Word.
<#Union-9>        nif:anchorOf "Union";          a nif:Word.
<#work-horse>     nif:anchorOf "work horse";     a nif:Phrase.
<#European-Union> nif:anchorOf "European Union"; a nif:Phrase.

############################## Stemming/Lemmatization
<#Germany-1>    nif:lemma "Germany". # same for all words, except:
<#European-8>   nif:lemma "Europe".

# For a more interesting example, let's assume there's a 10th word "favourite".
<#favourite-10> nif:stem  "favourit". # Snowball Stemmer
<#favourite-10> nif:lemma "favorite". # Stanford Core NLP
#+END_SRC

** Part of Speech
Let's represent some POS info using the Penn tagset.
It is part of the [[http://www.acoli.informatik.uni-frankfurt.de/resources/olia/][OLIA Ontologies]], and below we refer to files from that page.

The [[http://nlp.stanford.edu:8080/parser/index.jsp][Penn parser]] produces his parse:
: Germany/NNP is/VBZ the/DT work/NN horse/NN of/IN the/DT European/NNP Union/NNP
We represent it below using two properties:
- ~nif:oliaLink~ is an ~owl:Individual~ representing the individual tag
- ~nif:oliaCategory~ is an ~owl:Class~ representing the same
Since in ~penn.owl~ the individuals have the same ~rdf:type~ as the given class, you only need one, the other is redundant.
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#Germany-1>   nif:oliaLink penn:NNP; nif:oliaCategory penn:ProperNoun.
<#is-2>        nif:oliaLink penn:VBZ; nif:oliaCategory penn:BePresentTense.
<#the-3>       nif:oliaLink penn:DT;  nif:oliaCategory penn:Determiner.
<#work-4>      nif:oliaLink penn:NN;  nif:oliaCategory penn:CommonNoun. # POS is NN, but the syntactic role is Adjective
<#horse-5>     nif:oliaLink penn:NN;  nif:oliaCategory penn:CommonNoun.
<#of-6>        nif:oliaLink penn:IN;  nif:oliaCategory penn:PrepositionOrSubordinatingConjunction.
<#the-7>       nif:oliaLink penn:DT;  nif:oliaCategory penn:Determiner.
<#European-8>  nif:oliaLink penn:NNP; nif:oliaCategory penn:ProperNoun.
<#Union-9>     nif:oliaLink penn:NNP; nif:oliaCategory penn:ProperNoun.
#+END_SRC

One could consume POS at a higher level of abstraction: OLIA abstracts the particular POS tagset.
~penn-link.owl~ defines Penn classes as subclasses of OLIA classes, so one could consume OLIA only.
If you produce a reduced tagset (eg only ProperNouns), use the OLIA class directly.
Please note that ~nif:oliaLink~ (the individual) doesn't apply here, only  ~nif:oliaCategory~ (the class).

#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#Germany-1>   nif:oliaCategory olia:ProperNoun.
<#is-2>        nif:oliaCategory [owl:unionOf (olia:FiniteVerb olia:StrictAuxiliaryVerb)],
                             [a owl:Restriction; owl:onProperty olia:hasTense; owl:allValuesFrom olia:Present].
<#the-3>       nif:oliaCategory penn:Determiner. # "Not clear whether this corresponds to OLiA/EAGLES determiners"
<#work-4>      nif:oliaCategory olia:CommonNoun.
<#horse-5>     nif:oliaCategory olia:CommonNoun.
<#of-6>        nif:oliaCategory [owl:unionOf (olia:Preposition olia:SubordinatingConjunction)].
<#the-7>       nif:oliaCategory penn:Determiner. # "Not clear whether this corresponds to OLiA/EAGLES determiners"
<#European-8>  nif:oliaCategory olia:ProperNoun.
<#Union-9>     nif:oliaCategory olia:ProperNoun.
#+END_SRC

As you see above, the OLIA abstraction doesn't work perfectly in all cases:
- ~penn:Determiner~ doesn't have an OLIA mapping
- ~penn:PrepositionOrSubordinatingConjunction~ maps to a ~unionOf~ (disjunction), but you can't query by such class
- ~penn:BePresentTense~ is worse: it's also a ~unionOf~;
  further a reasoner will restrict any ~olia:hasTense~ property to have type ~olia:Present~.
  But neither OLIA nor Penn define any values for that property!

Rather than using the PENN-OLIA mapping, we could attach NLP features directly to words, eg
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#is-2> a olia:Verb;
  olia:hasTense ex:VerySpecialPresentTense.
ex:VerySpecialPresentTense a olia:Present, olia:Tense.
#+END_SRC

** Dependency Parse
The [[http://nlp.stanford.edu:8080/parser/index.jsp][Stanford Dependency Parser]] produces the following parse:
: (ROOT
:   (S
:     (NP (NNP Germany))
:     (VP (VBZ is)
:       (NP
:         (NP (DT the) (NN work) (NN horse))
:         (PP (IN of)
:           (NP (DT the) (NNP European) (NNP Union)))))))
A while ago the details of the parse were (currently it's a bit different):
| individual(gov,dep)      | class<superclass<superclass                                            |
|--------------------------+--------------------------------------------------------------------------|
| nsubj(horse-5,Germany-1) | NominalSubject<Subject<Argument<Dependent<DependencyLabel                |
| cop(horse-5,is-2)        | Copula<Auxiliary<Dependent<DependencyLabel                               |
| det(horse-5,the-3)       | Determiner<Modifier<Dependent<DependencyLabel                            |
| nn(horse-5,work-4)       | NounCompoundModifier<Modifier<Dependent<DependencyLabel                  |
| root(ROOT-0,horse-5)     | Root<DependencyLabel                                                     |
| prep(horse-5,of-6)       | PrepositionalModifier<Modifier<Dependent<DependencyLabel                 |
| det(Union-9,the-7)       | Determiner<Modifier<Dependent<DependencyLabel                            |
| amod(Union-9,European-8) | AdjectivalModifier<Modifier<Dependent<DependencyLabel                    |
| pobj(of-6,Union-9)       | ObjectOfPreposition<Object<Complement<Argument<Dependent<DependencyLabel |
*individual* is an ~owl:Individual~ having the class (and all superclasses) as its type

There are two ways to represent this:
- The easy way: use a single property (~nif:dependency~), attach the Stanford Dependency class to target
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#horse-5> nif:dependency <#Germany-1>.  <#Germany-1>  a stanford:NominalSubject.
<#horse-5> nif:dependency <#is-2>.       <#is-2>       a stanford:Copula.
<#horse-5> nif:dependency <#the-3>.      <#the-3>      a stanford:Determiner.
<#horse-5> nif:dependency <#work-4>.     <#work-4>     a stanford:NounCompoundModifier.
<#ROOT-0>  nif:dependency <#horse-5>.    <#horse-5>    a stanford:Root.
<#horse-5> nif:dependency <#of-6>.       <#of-6>       a stanford:PrepositionalModifier.
<#Union-9> nif:dependency <#the-7>.      <#the-7>      a stanford:Determiner.
<#Union-9> nif:dependency <#European-8>. <#European-8> a stanford:AdjectivalModifier.
<#of-6>    nif:dependency <#Union-9>.    <#Union-9>    a stanford:ObjectOfPreposition.
#+END_SRC

- The hard way: make separate DependencyLabel nodes
We use ~<#individual(gov,dep)>~ as URL: that includes numbered words, so is guaranteed to be unique.
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#nsubj(horse-5,Germany-1)> a olia:Relation, stanford:NominalSubject;        olia:hasSource <#horse-5>; olia:hasTarget <#Germany-1>.
<#cop(horse-5,is-2)>        a olia:Relation, stanford:Copula;                olia:hasSource <#horse-5>; olia:hasTarget <#is-2>.
<#det(horse-5,the-3)>       a olia:Relation, stanford:Determiner;            olia:hasSource <#horse-5>; olia:hasTarget <#the-3>.
<#nn(horse-5,work-4)>       a olia:Relation, stanford:NounCompoundModifier;  olia:hasSource <#horse-5>; olia:hasTarget <#work-4>.
<#root(ROOT-0,horse-5)>     a olia:Relation, stanford:Root;                  olia:hasSource <#ROOT-0>;  olia:hasTarget <#horse-5>.
<#prep(horse-5,of-6)>       a olia:Relation, stanford:PrepositionalModifier; olia:hasSource <#horse-5>; olia:hasTarget <#of-6>.
<#det(Union-9,the-7)>       a olia:Relation, stanford:Determiner;            olia:hasSource <#Union-9>; olia:hasTarget <#the-7>.
<#amod(Union-9,European-8)> a olia:Relation, stanford:AdjectivalModifier;    olia:hasSource <#Union-9>; olia:hasTarget <#European-8>.
<#pobj(of-6,Union-9)>       a olia:Relation, stanford:ObjectOfPreposition;   olia:hasSource <#of-6>;    olia:hasTarget <#Union-9>.
#+END_SRC

We use the following class hierarchy: ~stanford:DependencyLabel<olia_sys:Feature<LinguisticAnnotation~
The latter is kind of like ~Relation~, which has properties ~hasSource, hasTarget~

** NER Classes
There are two mechanisms to represent Named Entity Recognition.

If you can recognize only the entity type:
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#Germany-1>      itsrdf:taClassRef nerd:Country.
<#European-Union> itsrdf:taClassRef nerd:Country. # or AdministrativeRegion or Location
#+END_SRC

This uses the NERD ontology, which includes:
- NERD Core (top-level) classes:
  Thing Amount Animal Event Function Location Organization Person Product Time
- NERD specific classes:
  AdministrativeRegion Aircraft Airline Airport Album Ambassador Architect Artist Astronaut Athlete Automobile Band Bird Book Bridge Broadcast Canal Celebrity City ComicsCharacter Company Continent Country Criminal Drug EducationalInstitution EmailAddress FictionalCharacter Holiday Hospital Insect Island Lake Legislature Lighthouse Magazine Mayor MilitaryConflict Mountain Movie Museum MusicalArtist Newspaper NonProfitOrganization OperatingSystem Park PhoneNumber PoliticalEvent Politician ProgrammingLanguage RadioProgram RadioStation Restaurant River Road SchoolNewspaper ShoppingMall SoccerClub SoccerPlayer Software Song Spacecraft SportEvent SportsLeague SportsTeam Stadium Station TVStation TennisPlayer URL University Valley VideoGame Weapon Website

** NER Individuals
If you can recognize specific entities in LOD datasets, you can capture such annotations, eg:
- Wordnet RDF for phrases: [[http://wordnet-rdf.princeton.edu/search?query%3Dworkhorse][search Wordnet]], then pick the correct sense ~104608649-n~
- DBpedia for real-word entities
- Babelnet for phrases or real-word entities: [[http://babelnet.org/search?word%3Dworkhorse&lang%3DEN][search Babelnet]], then pick the correct sense ~00081596n~
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#work-horse>     itsrdf:taIdentRef
  <http://wordnet-rdf.princeton.edu/wn31/104608649-n>, bn:s00081596n.
<#Germany-1>      itsrdf:taIdentRef dbr:Germany.
<#European-Union> itsrdf:taIdentRef dbr:European_union.

dbr:European_union a dbo:Country, dbo:Place, dbo:PopulatedPlace, yago:G20Nations, yago:InternationalOrganizationsOfEurope. # etc
dbr:Germany        a dbo:Country, dbo:Place, dbo:PopulatedPlace, yago:FederalCountries, yago:EuropeanUnionMemberEconomies. # etc
#+END_SRC

These LOD sources include useful info, eg:
- Wordnet's [[http://wordnet-rdf.princeton.edu/wn31/104608649-n.ttl][104608649-n.ttl]] has:
  - wn:gloss "machine that performs dependably under heavy use"
  - wn:sample "the IBM main frame computers have been the workhorse of the business world"
  - declared owl:sameAs [[http://www.w3.org/2006/03/wn/wn20/instances/synset-workhorse-noun-1][older Wordnet 2.0 representation]]  and [[http://lemon-model.net/lexica/uby/wn/WN_Synset_25709][newer LemonUby representation]]
- DBpedia has info about population, area, etc.
  It also has extensive class info as shown above, so there's no need to use ~itsrdf:taClassRef nerd:Country~.
  But other NERD classes may be useful, eg Phone, Email: for those you can't refer to DBpedia and must use ~itsrdf:taClassRef~
- Babelnet has links to Wordnet, DBpedia, Wikipedia categories, skos:broader exracted from Wordnet/DBpedia, etc.
  The Multisensor Entity Lookup service uses Babelnet since it's a more modern resource integrating the two above, plus more

** NER Provenance
TODO: reconcile with what we currently use (fise:confidence vs nif-ann:taConfidence)
We can record the tool that created the NER annotation and its confidence in one of two ways:
- Simple case: only one annotation from one NER tool
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#Germany-1>
  itsrdf:taAnnotatorsRef <http://linguatec.com>;
  itsrdf:taConfidence 0.9. # same as "0.9"^^xsd:double
#+END_SRC

- Complex case: several annotations or NER tools. 
Need to use a separate node for each annotation, and the NIF Stanbol profile (FISE) instead of ITSRDF
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<#Germany-1-enrichment-1>
  a fise:EntityAnnotation;
  fise:extracted-from <#Germany-1>;
  fise:entity-type nerd:Country;
  fise:entity-reference dbr:Germany; # if you can recognize only the entity type, skip this
  dct:creator <http://linguatec.com>;
  fise:confidence "0.9"^^xsd:float.
#+END_SRC

I think it's a very bad practice to use two completely different property sets for these two situations.
Just because in the second case there's an intermediate node for the annotation,
doesn't mean the properties should be completely different: [[https://github.com/NLP2RDF/specification/issues/2][specification/issues/2]]

** Sentiment Analysis with MARL
Assume there are some comments about our blog, which we represent using SIOC.
Comments are a sort of ~sioc:Post~, since there is no separate ~sioc:Comment~ class
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<comment/1> a sioc:Post;
  sioc:reply_of <>;
  sioc:has_creator <http://example.com/users/Hans>;
  sioc:content "Yes, we Germans are the hardest-working people in the world".
<comment/2> a sioc:Post;
  sioc:reply_of <>;
  sioc:has_creator <http://example.com/users/Dimitrios>;
  sioc:content "Bullshit! We Greeks are harder-working".
#+END_SRC

Now assume a sentiment analysis algorithm detects the sentiment of the comment posts.
We represent them using MARL. 
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<opinion/1> a marl:Opinion;
  marl:extractedFrom <comment/1>;
  marl:describesObject <>;
  marl:opinionText "Yes";
  marl:polarityValue 0.9;
  marl:minPolarityValue -1;
  marl:maxPolarityValue 1;
  marl:hasPolarity marl:Positive.
<opinion/2> a marl:Opinion;
  marl:extractedFrom <comment/2>;
  marl:describesObject <>;
  marl:opinionText "Bullshit!";
  marl:polarityValue -1;
  marl:minPolarityValue -1;
  marl:maxPolarityValue 1;
  marl:hasPolarity marl:Negative.
#+END_SRC

Note: the following properties are useful for sentiment about vendors (eg AEG) or products (eg appliances):
- ~marl:describesObject~ (eg laptop)
- ~marl:describesObjectPart~ (eg battery, screen)
- ~marl:describesFeature~ (eg for battery: battery life, weight)

Often it's desirable to aggregate opinions, so one doesn't have to deal with individual opinions
(~marl:aggregatesOpinion~ is optional)
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<opinions> a marl:AggregatedOpinion;
  marl:describesObject <>;
  marl:aggregatesOpinion <opinion/1>, <opinion/2>; # can skip
  marl:opinionCount 2;
  marl:positiveOpinionsCount 1; # sic, this property is spelled in plural
  marl:negativeOpinionCount 1;
  marl:polarityValue -0.05; # simple average
  marl:minPolarityValue -1;
  marl:maxPolarityValue 1;
  marl:hasPolarity marl:Neutral.
#+END_SRC

** Sentiment Analysis in NIF
NIF integrates MARL using property ~nif:opinion~ from ~nif:String~ to ~marl:Opinion~.
But that's declared inverseOf ~marl:extractedFrom~, which in the MARL example points to ~sioc:Post~ (not the ~nif:String~ content of the post).
So something doesn't mesh here ([[https://github.com/NLP2RDF/specification/issues/1][specification/issues/1]]).
We could mix SIOC and NIF properties on ~<comment/1>~, but then ~nif:sourceUrl~ would point to itself...

#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<comment/1> a nif:Context;
  nif:sourceUrl <comment/1>;
  nif:isString "Yes, we Germans are the hardest-working people in the world";
  nif:opinion <opinion/1>.
<comment/2> a nif:Context;
  nif:sourceUrl <comment/2>;
  nif:isString "Bullshit! We Greeks are harder-working";
  nif:opinion <opinion/2>.
#+END_SRC

It may be more meaningful to use NIF to express which word carries the opinion (like ~marl:opinionText~)
#+BEGIN_SRC Turtle :tangle ./img/NIF-example.ttl
<comment/1#char=0,> a nif:Context;
  nif:sourceUrl <comment/1>;
  nif:isString "Yes, we Germans are the hardest-working people in the world".
<comment/1#char=0,3> a nif:String;
  nif:referenceContext <comment/1#char=0,>;
  nif:anchorOf "Yes";
  nif:opinion <opinion/1>.

<comment/2#char=0,> a nif:Context;
  nif:sourceUrl <comment/2>;
  nif:isString "Bullshit! We Greeks are harder-working".
<comment/2#char=0,9> a nif:String;
  nif:referenceContext <comment/2#char=0,>;
  nif:anchorOf "Bullhshit!";
  nif:opinion <opinion/2>.
#+END_SRC


* RDF Validation
All generated NIF files should be validated, to avoid mistakes propagating between the pipeline modules.

** NIF Validator
The basic NIF validator is part of the NIF distribution ([[http://persistence.uni-leipzig.org/nlp2rdf/specification/core.html#validator][doc]], [[http://persistence.uni-leipzig.org/nlp2rdf/specification/validate.jar][software]], [[http://persistence.uni-leipzig.org/nlp2rdf/ontologies/testcase/lib/nif-2.0-suite.ttl][tests]]).
Unfortunately there are only 11 tests, so it's not very useful
- You can understand the tests just by reading the error messages, e.g. 
  : nif:anchorOf must match the substring of nif:isString calculated with begin and end index
- It says "informat=json-ld not implemented yet", so we need to convert to ttl first (I use apache-jena-2.12.1)
  : rdfcat -out ttl test-out.jsonld | java -jar validate.jar -i - -o text

** RDFUnit Validation
A much better validator is RDFUnit ([[http://aksw.org/Projects/RDFUnit.html][home]], [[http://rdfunit.aksw.org/demo/][demo]], [[https://github.com/AKSW/RDFUnit/][source]], paper [[http://jens-lehmann.org/files/2014/eswc_rdfunit_nlp.pdf][NLP data cleansing based on Linguistic Ontology constraints]])
This is implemented in the Multisensor [[http://mklab2.iti.gr/multisensor/index.php/RDF_Validation_Service][RDF_Validation_Service]]

I tried their demo site with [[./img/NIF-test1.jsonld]] and [[./img/NIF-example2.ttl]]:
1. Data Selection> Direct Input> JSON-LD> Load
  : Data loaded successfully! (162 statements)
2. Constraints Selection> Automatic> Load
  : Constraints loaded successfully: (foaf, nif, itsrdf, dcterms)
3. Test Generation
  : Completed! Generated 514 tests                 
  (That's a lot of tests!)
4. Testing> Report Type> Status (all)> Run Tests
  : Total test cases 514, Succeeded 507, Failed 7  
  (Those "Succeeded" also in many cases mean errors)

*** Generated Tests per Ontology
| URI                                                             | Automatic | Manual |
|-----------------------------------------------------------------+-----------+--------|
| http://xmlns.com/foaf/0.1/                                      |       174 | -      |
| http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core# |       199 | 10     |
| http://www.w3.org/2005/11/its/rdf#                              |        75 | -      |
| http://purl.org/dc/terms/                                       |        56 | -      |
| http://www.w3.org/2006/time#                                    |       183 | -      |
| http://dbpedia.org/ontology/                                    |      9281 | 14     |
(Even though I canceled dbo generation prematurely.)

This is too much for us, we don't want the DBO tests.
In particular, the *Status (all)* report includes a lot of "violations" that come from ontologies not from our data.

*** RDFUnit Test Results
Here are the results. "Resources" is a simple tabular format (basically URL-error),
"Annotated Resources" provides more detail (about the errors pertaining to each URL)
- [[./NIF-test1-out.xls]]: Status (all) and Resources
- [[./NIF-test1-annotated.ttl]]: Annotated Resources
- [[./NIF-example2-out.xls]]: Resources
- [[./NIF-example2-annotated.ttl]]: Annotated Resources

** Manual Validation
We have used a lot of manual validation to check for semantic (as opposed to syntactic) errors.
The [[http://mklab2.iti.gr/multisensor/index.php/RDF_Validation][RDF_Validation]] page describes a workflow for preparing pipeline results for validation.

Please post only Turtle files, not JSON files since they are impossible to check manually.
- Get Jena (eg [[http://apache.cbox.biz/jena/binaries/apache-jena-3.0.0.tar.gz][apache-jena-3.0.0.tar.gz]]), unzip it somewhere and add the bin directory to your path. We'll use RIOT (RDF I/O Tool).
- Get Turtle: You can get a Turtle representation of the SIMMO in one of two ways

*** Get Turtle from Store
- Store the SIMMO using the [[http://mklab2.iti.gr/multisensor/index.php/RDF_Storing_Service][RDF Storing Service]]
- Get the SIMMO out using a query like this (saved as "a SIMMO graph"), and then save the result as ~file-noprefix.ttl~ (Turtle).
#+BEGIN_SRC sparql
<pre>construct {?s ?p ?o} 
where {graph <http://data.multisensor.org/content/8006dcd60b292feaaef24abc9ec09e2230aab83e> 
  {?s ?p ?o}}
#+END_SRC
- There's also a REST call to get the SIMMO out that's easier to use from the command line

*** Get Turtle from SIMMO JSON
- get the content of the "rdf" key out of the SIMMO JSON. Unescape quotes. Save as ~file.jsonld~
  So instead of this:
  #+BEGIN_SRC javascript
  "rdf":["[{\"@id\":\"http://data.multisensor...[{\"@value\":\"Germany\"}]}]"],"category":""}</pre>
  #+END_SRC
  You need this:
  #+BEGIN_SRC javascript
  [{"@id":"http://data.multisensor...[{"@value":"Germany"}]}]
  #+END_SRC
- You can do this manually, or with RIOT that can convert the stringified RDF field into more readable JSONLD format:
  : riot --output=jsonld rdf_output_string.jsonld > new_readable_file.jsonld
  Instead of a single string, the results will be displayed as:
  #+BEGIN_SRC javascript
  "@graph" : [ {
    "@id" : "http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304#Amount=10000_Euro",
    "@type" : [ "http://schema.org/QuantitativeValue", "http://nerd.eurecom.fr/ontology#Amount" ],
    "name" : "10000 Euro"
  }, {
    "@id" : "http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304#Amount=2000_Euro",
    "@type" : [ "http://schema.org/QuantitativeValue", "http://nerd.eurecom.fr/ontology#Amount" ],
    "name" : "2000 Euro"
  }, {...  
  #+END_SRC

No matter which of the two methods you used, the rest is the same
- Validate it with RIOT: this is optional but recommended
  : riot --validate file.jsonld
- Convert to Turtle. Omit "WARN riot" lines which would make the Turtle invalid
 : riot --output turtle file.jsonld | grep -v "WARN  riot" > file-noprefix.ttl

**** Prettify Turtle
Unfortunately this file doesn't use prefixes, so the URLs are long and ugly (Boyan will fix this for the Store [[https://quark.everis.com/jira/browse/MULTISENSO-137][MULTISENSO-137]])
- Download [[./img/prefixes.ttl]] (this file is updated about once a month)
- Concat the two:
  : cat prefixes.ttl file-noprefix.ttl > file-withprefix.ttl
- Prettify the Turtle to make use of the prefixes and to group all statements of the same subject together:
  : riot --formatted=turtle file-withprefix.ttl > file.ttl

Optional manual edits:
- Add on top a base, using the actual SIMMO base, eg
  : @base <http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304>.
- Replace this string with "" (I don't know why RIOT doesn't use the base, even if I specify the --base option)
- Sort paragraphs (i.e. statement clusters)

Post in Jira that last prettified file.ttl. Thanks!

* Graph Handling
** TODO Storing Service PUT vs POST
Please note that the ASR is written in the same graph as the SIMMO. 
PUT rewrites the graph: https://www.w3.org/TR/sparql11-http-rdf-update/#http-put.
So you should use a sequence like this:
- PUT SIMMO
- POST ASR0
- POST ASR1
- POST image annotation

** Graph Normalization
The [[http://mklab2.iti.gr/multisensor/index.php/RDF_Storing_Service][RDF_Storing_Service]] saves all data about a SIMMO in a named graph having the same URL as the SIMMO base URL.
This makes it easy to get all data about the SIMMO.
But it also leads to duplication of common triples. Eg consider this:
#+BEGIN_SRC Turtle
<http://multisensor.org/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c30488#char=100,107> its:taIdentRef dbr:Germany.

# Common triples
dbr:Germany a nerd:Location;
  foaf:name "Germany"
#+END_SRC
If ~dbr:Germany~ appears 1000 times in SIMMOs, these common triples will be duplicated 1000 times.
This leads to extreme slowness of ElasticSearch indexing:
when adding the 1000th occurrence of ~dbr:Germany~ it indexes (the same) foaf:name "Germany" 1000 times,
i.e. storing time grows potentially quadratically with the number of SIMMOs.

The proposed fix is *graph normalization*: the storing service examines every triple ~<s,p,o>~.
- If ~s~ starts with one of these prefixes the triple is stored in the default graph:
  : http://dbpedia.org
  : http://babelnet.org
- Otherwise the triple is stored in the SIMMO graph.
This still writes common triples 1000 times,
but there is no duplication since a triple can exist only once in a given graph.
- Note: some SIMMOs contain subjects that don't have the SIMMO base URL as prefix,
  namely embedded videos and images.
  It's not correct to move them to the default graph, so we work with an explicit list of common prefixes.

*** Query Changes
The tradeoff is that you won't be able to get all SIMMO data by simply asking for a graph.
Eg query [[https://docs.google.com/document/d/1FfkiiTYvrLzHJ5P5j34NRVGPbXml0ndpNtiNbH2osRw/edit#heading%3Dh.ngkjkg5b5zze][2.3 Retrieve NEs (Select)]] is a bit sloppy, since it asks for certain types (and ~foaf:name~) by graph, without looking for any relation:
#+BEGIN_SRC sparql
SELECT DISTINCT ?ne ?type ?name {
  GRAPH <http://data.multisensor.org/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c30488> {
    ?ne a ?type; foaf:name ?name
    FILTER (?type IN (dbo:Person, dbo:Organization, nerd:Amount, nerd:Location, nerd:Time))}}
#+END_SRC

If graph normalization is applied, we'd have to find the NEs by relation ~its:taIdentRef~,
and get their common triples from outside the SIMMO graph:
#+BEGIN_SRC sparql
SELECT distinct ?ne ?type ?name {
  GRAPH <http://multisensor.org/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c30488>
    {[] its:taIdentRef ?ne}
  ?ne a ?type; foaf:name ?name
  FILTER (?type IN (dbo:Person, dbo:Organization, nerd:Amount, nerd:Location, nerd:Time))
}
#+END_SRC
(Actually this query also works before graph normalization since the part outside ~GRAPH {..}~ looks in all graphs, both SIMMO and default).

*** Normalization Problems
Moving common triples outside of the SIMMO graph raises two problems:
- If you examine the results of the query above, you'll see that some entities (eg ~dbr:Facebook~) have several labels, eg
  : "Facebook, Inc."@en
  : "Facebook"^^xsd:string
  The reason is probably that different SIMMOs have different versions of the label, and different versions of the pipeline emit different literals ("en" language vs xsd:string).
  Both of these labels will be indexed in ElasticSearch for all occurrences of this NE.
  But the pipeline has emitted the labels globally (as ~foaf:name~ of ~dbr:Facebook~) rather than locally (eg as ~nif:anchorOf~),
  in effect asserting that both are globally valid labels of Facebook.
  So that's a correct consequence of the data as emitted.
- If the last SIMMO referring to a global NE is deleted, that NE will remain as "garbage" in the common graph.
  But I don't think that is a significant problem, since the amount of such "garbage" won't be large, and since it is harmless.

*Are the partners willing to make this change to the data model, and change their queries correspondingly?*

* SIMMO
Multisensor crawls and analyzes news items and social network posts, collectively called SIMMOs.
Each SIMMO has a GUID URL in the ~ms-content:~ namespace.
All SIMMO statements are stored in a separate graph, having the same URL.
Below we have set the ~@base~ to the SIMMO URL, so ~<>~ and ~ms-content:<GUID>~ mean the same URL.

The basic structure of a SIMMO consists of the following.
We use ~dc:~ for literals and ~dct:~ for resources (URLs).
#+BEGIN_SRC Turtle
@base <http://data.multisensorproject.eu/content/04858f1e0cbc73ab672b1f6acab05afe2c18b0ae>
graph ms-content:04858f1e0cbc73ab672b1f6acab05afe2c18b0ae {
  <> a foaf:Document;
    dc:type "article";
    dc:language "en";
    dbp:countryCode "GB";
    dc:source "Guardian";
    dct:source <https://www.theguardian.com/uk-news/2016/jun/20/zane-gbangbola-inquest-neighbour-hydrogen-cyanide>;
    dc:creator "Caroline Davies";
    dc:date    "2016-06-20T18:45:07.000+02:00"^^xsd:dateTime;
    dct:issued "2016-06-30T12:34:56.000+02:00"^^xsd:dateTime; 
    dc:title "I was told I might have 20 minutes to live, neighbour tells Zane inquest" ;
    dc:description "Zanes parents Kye Gbangbola (front centre) and Nicole Lawler (right) at a protest...";
    dc:subject "Lifestyle & Leisure";
    schema:keywords "UK news, Zane Gbangbola, Hydrogen Cyanide".

<#char=0,5307> a nif:RFC5147String, nif:Context;
  nif:sourceUrl <> .
  nif:beginIndex "0"^^xsd:nonNegativeInteger;
  nif:endIndex "5307"^^xsd:nonNegativeInteger;
  nif:isString """I was told I might have 20 minutes to live, neighbour tells Zane inquest
Zanes parents Kye Gbangbola (front centre) and Nicole Lawler (right) at a protest in 2014.
Photograph: Lauren Hurley/PA ...""".
}
#+END_SRC
Explanation:
| element         | meaning                                                         |
|-----------------+-----------------------------------------------------------------|
| *foaf:Document* | Basic SIMMO metadata                                            |
| dc:type         | kind of SIMMO                                                   |
| dc:language     | Language of content                                             |
| dbp:countryCode | Code of originaing country                                      |
| dc:source       | Literal identifying the source (newspaper or social network)    |
| dct:source      | URL of source article                                           |
| dc:creator      | Author: journalist, blogger, etc                                |
| dc:date         | Timestamp when crawled                                          |
| dct:issued      | Timestamp when processed by pipeline and ingested to GraphDB    |
| dc:title        | Short title                                                     |
| dc:description  | Longer description                                              |
| dc:subject      | Article subject, roughly corresponding to [[http://cv.iptc.org/newscodes/subjectcode][IPTC Subject Codes]]    |
| schema:keywords | Free keywords                                                   |
|-----------------+-----------------------------------------------------------------|
| *nif:Context*   | "Reference Context": holds the full text, root of all NIF data. |
|                 | Each word/sentence points to it using nif:referenceContext      |
|                 | The URL ~#char=<beg,end>~ follows RFC 5147                      |
| nif:sourceUrl   | Points to the SIMMO                                             |
| nif:beginIndex  | Always 0 for this node. A xsd:nonNegativeInteger                |
| nif:endIndex    | Length of the text                                              |
| nif:isString    | The full text                                                   |


* Multisensor Named Entity Recognition
This section describes the representation of NER in Multisensor

** NER Mapping
Multisensor recognizes a number of Named Entity types. The following table specifies potential NE properties and what they are mapped to.
| *Class* /Property | *Type/enum*      | *Mapping*                                              | *Notes*                                                     |
|-------------------+------------------+--------------------------------------------------------+-------------------------------------------------------------|
| *all*             |                  | nif:Word or nif:Phrase                                 |                                                             |
| text              | string           | n/a                                                    | nif:anchorOf omitted                                        |
| onset             | number           | nif:beginIndex                                         | start                                                       |
| offset            | number           | nif:endIndex                                           | end                                                         |
| *Person*          |                  | dbo:Person, foaf:Person; nerd:Person                   |                                                             |
| test              | string           | foaf:name                                              |                                                             |
| firstname         | string           | foaf:firstName                                         |                                                             |
| lastname          | string           | foaf:lastName                                          |                                                             |
| gender            | male, female     | dbo:gender                                             | dbp:Male, dbp:Female                                        |
| occupation        | string           | rdau:professionOrOccupation                            | dbo:occupation and dbo:profession are object props          |
| *Location*        | type=other       | nerd:Location                                          | No need to use dbo:Location if you can't identify the type  |
| *Location*        | type=country     | dbo:Country; nerd:Country                              |                                                             |
| *Location*        | type=region      | dbo:Region; nerd:AdministrativeRegion                  |                                                             |
| *Location*        | type=city        | dbo:City; nerd:City                                    |                                                             |
| *Location*        | type=street      | schema:PostalAddress; nerd:Location                    | Put text in schema:streetAddress                            |
| *Organisation*    | type=institution | dbo:Organisation, foaf:Organization; nerd:Organization |                                                             |
| *Organisation*    | type=company     | dbo:Company, foaf:Company; nerd:Company                |                                                             |
| *Product*         |                  | nerd:Product                                           |                                                             |
| type              | string           | not yet                                                | don't know yet what makes sense here                        |
| *Time*            |                  | time:Instant; nerd:Time                                | TODO: can you parse to XSD datetime components?             |
| year              | string           | time:Instant; nerd:Time                                |                                                             |
| month             | string           | time:Instant OR yago:Months; nerd:Time                 | if yago:Months then dbp:January...                          |
| day               | string           | time:Instant; nerd:Time                                |                                                             |
| time              | string           | time:Instant; nerd:Time                                |                                                             |
| weekday           | string           | yago:DaysOfTheWeek; nerd:Time                          | dbp:Sunday,... Put text in rdfs:label                       |
| rel               | string           | nerd:Time                                              | relative expression, eg "the last three days"               |
| other             | string           | nerd:Time                                              | any other time expression, eg "Valentine's day"             |
| *Amount*          | type=price       | schema:PriceSpecification; nerd:Amount                 |                                                             |
| unit              | string           | schema:priceCurrency                                   | 3-letter ISO 4217 format                                    |
| amount            | number           | schema:price                                           | "." as decimal separator                                    |
| *Amount*          | type=unit        | schema:QuantitativeValue; nerd:Amount                  | How about percentage??                                      |
| unit              | string           | schema:unitCode                                        | Strictly speaking, UN/CEFACT Common Code (eg GRM for grams) |
| amount            | number           | schema:value                                           |                                                             |
| *Name*            |                  | nerd:Thing                                             |                                                             |
| type              | string           | dc:type                                                | a type if anything can be identified, otherwise empty       |

Notes
- Classes are uppercase, Properties are lowercase
- NERD classes are attached to the word using itsrdf:taClassRef
- Other classes are attached to the NE node (itsrdf:taIdentRef) using rdf:type.
- the Amount mapping uses schema.org classes/properties, which were borrowed from GoodRelations
- dbo:gender is an object property, though it doesn't specify the values to use
- dc:type is a literal. We attach it to the word directly
- don't forget to include itsrdf:taAnnotatorsRef (eg <http://linguatec.com>) for each

** Example
- [[./NIF-example3.ttl]]: Various kinds of Named Entities as per [[./Multisensor-NER-Mapping.html]]

[[./NIF-example3.ttl]] ([[./NIF-example3.ttl.html]]) and [[./NIF-example3.jsonld]] include examples for each of the named entity kinds.
- I made up some word/phrase occurrences. I use nif:anchorOf to illustrate the
  word/phrase, and omit nif:beginIndex and nif:endIndex. In actual use, you'll do exactly
  the opposite (nif:anchorOf should be omitted since it's redundant)
- In a couple cases I've embedded rdfs:comment and rdfs:seeAlso to illustrate a point. Of
  course, don't emit such in the actual JSONLD

*** Named Entity URLs
We have the following options for Named Entity URLs:
1. Global: it's best to use global DBpedia URLs if they can be identified, as explained in [[./NIF-example2.ttl]]
   : http://dbpedia.org/resource/Angela_Merkel
2. Project: we could use a project-global namespace for entities, eg
   : http://www.multisensorproject.eu/entity/Person/Angela_Merkel
   (Eg the [[http://tag.ontotext.com]] demo uses such URLs for entities it cannot identify in global datasets).
   However, this won't allow different NEs with the same name across documents
3. Document: [[./NIF-example3.ttl]] uses per-document URLs, eg
   : http://www.multisensorproject.eu/content/12542546#Person=Angela_Merkel
   (In this and the previous option, the entity URI is made from the entity text, replacing punctuation with "_"). 
   This still does not allow two different John_Smiths in one document, but the chance of this happening is smaller.
Slash vs Hash: everyting after a # is fetched with one HTTP request.
- So hash is used for "sub-nodes" that will be typically be served with one HTTP request
- In contrast, slash is used with large collections. If we have a million Named Entities, we can't use hash in the *Project* scheme/

** TODO
Examples (a few more are explained in Multisensor-NER-Mapping):
- [[./NIF-example2.ttl]]: example of NER as produced by LT (doesn't yet include all fields from the NER Mapping above).
  - [[./NIF-example2.json]]: same in JSON-LD


* Relation Extraction
We represent Relation Extraction information using FrameNet. This more complex topic is developed in its own folder [[./FrameNet/]] and a paper:
- [[http://vladimiralexiev.github.io/Multisensor/FrameNet/paper.pdf][FN goes NIF: Integrating FrameNet in the NLP Interchange Format]]. Alexiev, V.; and Casamayor, G. In Linked Data in Linguistics (LDL-2016): Managing, Building and Using Linked Language Resources, Portoro, Slovenia, May 2016.
- Also see: [[http://vladimiralexiev.github.io/Multisensor/FrameNet/pres.html][interactive presentation]], [[http://vladimiralexiev.github.io/Multisensor/FrameNet/pres-full.html][continuous HTML]]

* Confidence and Provenance
Until recently the Multisensor pipeline used only one NER annotation tool (from Linguatec).
Consider the phrase "Phillips Imaging Systems". Linguatec correctly guesses a NER (Organization) and makes a local entity ~#Organization=Systems~ (but doesn't pick the whole phrase).
So we could capture the confidence and provenance of the annotation as follows:
#+BEGIN_SRC Turtle
<#char=1116,1123> a nif:Word;
  nif:anchorOf "Systems";
  itsrdf:taClassRef nerd:Organization;
  itsrdf:taIdentRef <#Organization=Systems>;
  itsrdf:taConfidence 0.9; # means the same as "0.9"^^xsd:decimal
  itsrdf:taAnnotatorsRef "text-analysis|http://linguatec.com".
#+END_SRC

** Multiple Annotations with FISE
Recenly we started adding annotations from a second tool (Babelfy).
So now potentially the same word or phrase can carry two annotations.
The same word "System" is recognized by Babelfy as http://babelnet.org/rdf/s00075759n, which is the general concept "Instrumentality that combines interrelated interacting artifacts".

The NIF+Stanbol profile (FISE) defines a model for this:\\
http://vladimiralexiev.github.io/Multisensor/20141008-Linguistic-LD/img/NIF-profiles.png

#+BEGIN_SRC Turtle
<#char=1116,1123> a nif:Word;
  nif:anchorOf "Systems".

<#char=1116,1123-annot-Linguatec> a fise:EntityAnnotation;
  fise:extracted-from <#char=1116,1123>;
  fise:entity-type nerd:Organization;
  fise:entity-reference <#Organization=Systems>;
  fise:confidence "0.9"^^xsd:float;
  dct:creator <http://linguatec.com>.

<#char=1116,1123-annot-Babelnet> a fise:EntityAnnotation;
  fise:extracted-from <#char=1116,1123>;
  fise:entity-reference bn:s00075759n;
  fise:confidence "0.95"^^xsd:float;
  dct:creator <http://babelfy.org>.
#+END_SRC

It's not nice that NIF+Stanbol uses completely different properties from the simple case, as we reported in [[https://github.com/NLP2RDF/specification/issues/2][NLP2RDF/specification#2]].

** Multiple Annotations with NIF 2.1 RC
Recently a new proposal "Provenance and Confidence for NIF annotations" was published, motivated by the FREME project.
It is part of a developing NIF 2.1 specification (currently at Release Candidate stage):
- published: http://nif.readthedocs.org/en/2.1-rc/prov-and-conf.html
- source: https://github.com/NLP2RDF/documentation/tree/2.1-RC/docs (last edit mid-Jan 2016, 3 months ago)

It is somewhat better than FISE, but we still don't know whether it's stable and can be relied upon (asked in [[https://github.com/NLP2RDF/documentation/issues/1][NLP2RDF/documentation#1]]).

The same annotations as in the previous section could be represented as follows:
#+BEGIN_SRC Turtle
<#char=1116,1123> a nif:Word;
  nif:anchorOf "Systems";
  nif:annotationUnit <#char=1116,1123-annot-Linguatec>, <#char=1116,1123-annot-Babelnet>.

<#char=1116,1123-annot-Linguatec> a nif:AnnotationUnit;
  itsrdf:taClassRef nerd:Organization
  itsrdf:taIdentRef <#Organization=Systems>; # local generated entity
  nif:confidence 0.9;
  nif:provenance <http://linguatec.com>.

<#char=1116,1123-annot-Babelnet> a nif:AnnotationUnit;
  itsrdf:taIdentRef bn:s00075759n; # general concept "System"
  nif:confidence 0.95;
  nif:provenance <http://babelfy.org>.
#+END_SRC

Note: the above is in accordance with section [[http://nif.readthedocs.org/en/2.1-rc/prov-and-conf.html#using-only-generic-provenance-and-confidence-properties][Using only Generic Provenance and Confidence Properties]].
The first section [[http://nif.readthedocs.org/en/2.1-rc/prov-and-conf.html#provenance-and-confidence-using-companion-properties][Using Companion Properties]] describes using different properties in pairs:
- nif:taClassConf & nif:taClassProv for itsrdf:taClassRef
- nif:taIdentConf & nif:taIdentProv for itsrdf:taIdentRef
However, the Linguatec annotation always emits both Class and Ident, so it's more appropriate to use the single (generic) properties.

** NIF 2.1 RC Backward Incompatibility

*FLASH update*: NIF 2.1 RC is still very unstable (development is ongoing at https://github.com/NLP2RDF/ontologies/tree/nif2.1). 
On 14 Mar 2016 a massive change was made ([[https://github.com/NLP2RDF/ontologies/commit/6a1685a13931d49c1ded294478e508b5836e2201][Modularisation of NIF]]) that split out relevant parts to [[https://github.com/NLP2RDF/ontologies/blob/nif2.1/nif-annotation/nif-annotation.ttl][nif-annotation.ttl]] and a separate namespace ~nif-ann:~. 
Commit notes:
- introduced a separated NIF Annotation ontology module
- added deprecation and redirection pointers for annotations vocab previously in NIF Core that was migrated to NIF Annotation
- introduced a NIF Incubator ontology document for tentative NIF parts
- moved translation vocabulary to NIF Incubator
It deprecated a bunch of elements in [[https://github.com/NLP2RDF/ontologies/blob/nif2.1/nif-core/nif-core.ttl][nif-core.ttl]] (namespace ~nif:~), so it's backward incompatible (posted as [[https://github.com/NLP2RDF/ontologies/issues/16][NLP2RDF/ontologies#16]]).
I think this one change will prevent us from using NIF 2.1 in Multisensor.

** Singling Out an Annotation
Both NIF+Stanbol and NIF 2.1 RC allow one annotation to be singled out and represented "inline" (in a direct way).
This is important, since the direct way is more economical, and this matters when we are considering millions of annotations.
NIF 2.1 RC specifically describes such case, relegating "alternative, less probable entity linking results" to an indirect representation.

Assume that in the above example, we single out the Linguatec annotation. 
We can represent this as follows in NIF+Stanbol:
#+BEGIN_SRC Turtle
<#char=1116,1123> a nif:Word;
  nif:anchorOf "Systems";
  # direct annotation
  itsrdf:taClassRef nerd:Organization;
  itsrdf:taIdentRef <#Organization=Systems>;
  itsrdf:taConfidence 0.9;
  itsrdf:taAnnotatorsRef "text-analysis|http://linguatec.com".

<#char=1116,1123-annot-Babelnet> a fise:EntityAnnotation;
  # indirect annotation
  fise:extracted-from <#char=1116,1123>;
  fise:entity-reference bn:s00075759n;
  fise:confidence "0.95"^^xsd:float;
  dct:creator <http://babelfy.org>.
#+END_SRC

We can also represent it in NIF 2.1 RC as follows:
#+BEGIN_SRC Turtle
<#char=1116,1123> a nif:Word;
  nif:anchorOf "Systems";
  # direct annotation
  itsrdf:taClassRef nerd:Organization
  itsrdf:taIdentRef <#Organization=Systems>; # local generated entity
  nif:confidence 0.9;
  nif:provenance <http://linguatec.com>;
  # indirect annotation
  nif:annotationUnit <#char=1116,1123-annot-Babelnet>.

<#char=1116,1123-annot-Babelnet> a nif:AnnotationUnit;
  itsrdf:taIdentRef bn:s00075759n; # general concept "System"
  nif:confidence 0.95;
  nif:provenance <http://babelfy.org>.
#+END_SRC

NIF 2.1 RC has the advantage that it uses the same properties in both the direct and indirect annotation.
In contrast, the NIF+Stanbol approach uses different properties and also:
- ~itsrdf:taAnnotatorsRef~ is not a URL but a specially formatted string (coming from the XML heritage of ITS, see [[https://www.w3.org/TR/its20/#annotators-ref-usage-scenarios][5.7 ITS Tools Annotation]])
- ~fise:confidence~ is specified as a xsd:float while itsrdf:taConfidence is xsd:decimal

*Remaining question*
- How to single out one annotation as "primary"
- How to inform the pipeline so the other annotations are made as indirect (~nif:AnnotationUnit~)
If we cannot do this dynamically, then we should emit the less numerous annotations using the indirect way.

* TODO Babelnet Concepts
The whole dataset is not available for download, but one can get the entities one by one.
We fetched all Babelnet entities found by EL, and their broaders. This is documented here and next section:
https://docs.google.com/document/d/1FfkiiTYvrLzHJ5P5j34NRVGPbXml0ndpNtiNbH2osRw/edit#heading=h.ox8sifjjf4q4
EL found 324k occurrences of 31k Babelnet entities, which grows to 46k when we get their broaders (recursively).

We recorded DBpedia, Wordnet and Geonames links, and DBpedia categories, e.g.:

bn:s00000002n  a                     skos:Concept ;
        bn-lemon:dbpediaCategory     <http://dbpedia.org/resource/Category:Populated_coastal_places_in_the_Netherlands> , <http://dbpedia.org/resource/Category:1248_establishments> , <http://dbpedia.org/resource/Category:Provincial_capitals_of_the_Netherlands> , <http://dbpedia.org/resource/Category:The_Hague> , <http://dbpedia.org/resource/Category:Populated_places_in_South_Holland> , <http://dbpedia.org/resource/Category:Populated_places_established_in_the_13th_century> , <http://dbpedia.org/resource/Category:Cities_in_the_Netherlands> , <http://dbpedia.org/resource/Category:Port_cities_and_towns_of_the_North_Sea> ;
        bn-lemon:synsetID            "bn:00000002n" ;
        bn-lemon:synsetType          "NE" ;
        bn-lemon:wiktionaryPageLink  wiktionary:The_Hague ;
        dcterms:license              <http://creativecommons.org/licenses/by-nc-sa/3.0/> ;
        lexinfo:partHolonym          bn:s00044423n ;
        skos:broader                 bn:s00064917n , bn:s00015498n , bn:s15898622n , bn:s03335997n , bn:s10245001n , bn:s00056922n , bn:s00019319n ;
        skos:exactMatch              freebase:m.07g0_ , lemon-Omega:OW_eng_Synset_22362 , lemon-WordNet31:108970180-n , dbpedia:The_Hague , yago:The_Hague , geonames:2747373 .

Together with the EN, ES, DE, BG labels that UPF recorded, thats plenty of info.


<#char=0,4-annot-BabelNet>
        a                   nif-ann:AnnotationUnit ;
        nif-ann:confidence  "0.0"^^xsd:double ;
        nif-ann:provenance  <http://babelfy.org/> ;
        its:taClassRef      ms:GenericConcept ;
        its:taIdentRef      bn:s00029050n .

<#char=0,4>
        a                        nif:Phrase , nif:Word ;
        nif-ann:annotationUnit   <#char=0,4-annot-BabelNet> ;
        nif:anchorOf             "East" ;
        nif:beginIndex           "0"^^xsd:nonNegativeInteger ;
        nif:dependency           <#char=5,11> ;
        nif:endIndex             "4"^^xsd:nonNegativeInteger ;
        nif:lemma                "east" ;
        nif:literalAnnotation    "deep=spos=NN" , "surf=spos=NN" , "rel==dpos=NN|end_string=4|id0=1|start_string=0|number=SG|word=east|connect_check=OK|vn=east" ;
        nif:oliaLink             upf-deep:NAME , upf-dep-syn:NAME , <#char=0,4_fe> , penn:NNP ;
        nif:referenceContext     <#char=0,12793> ;
        upf-deep:deepDependency  <#char=5,11> ;

** Generic vs Specific Concepts
The Concept Extraction Service makes a distinction between Generic vs Specific Babelnet concepts,
which is used by the Summarization service.
- Generic concepts
- Specific concepts are specific to the Multisensor domain,
  which are recognized by statistical analysis over the Multisensor SIMMO corpus.
Consider the following example: "Wind turbines are complex engineering systems":
- bn:s00081274n "wind turbine" is a specific concept, which we represent as ~nif:taClassRef ms:SpecificConcept~
- bn:s00075759n "system" is a generic concept, which we represent as ~nif:taClassRef ms:GenericConcept~
Comparing sec [[*Multiple Annotations with FISE]] where we used separate nodes for each annotation, 
here we use a single node per annotation:
#+BEGIN_SRC Turtle
<#char=0,45> a nif:Context;
  nif:isString "Wind turbines are complex engineering systems".

<#char=0,13> a nif:Phrase;
  nif:referenceContext <#char=0,45>;
  nif:beginIndex 0;
  nif:endIndex 13;
  nif:anchorOf "Wind turbines";
  nif:taIdentRef bn:s00081274n;
  nif:taClassRef ms:SpecificConcept.

<#char=38,45> a nif:Word;
  nif:referenceContext <#char=0,45>;
  nif:beginIndex 38;
  nif:endIndex 45;
  nif:anchorOf "system";
  nif:taIdentRef bn:s00075759n;
  nif:taClassRef ms:GenericConcept.
#+END_SRC

The Concept Extraction Service will also emit the labels of the recognized Babelnet concepts.
These will be put in the default graph, not in per-SIMMO graphs, see sec [[*Graph Normalization]].
Babelnet uses ~lemon:isReferenceOf~ and ~lemon:LexicalSense~ to express the labels, but we use a simpler representation with ~skos:prefLabel~:
#+BEGIN_SRC Turtle
bn:s00081274n a skos:Concept; skos:prefLabel "wind turbine"@en, "aerogenerador"@es.
bn:s00075759n a skos:Concept; skos:prefLabel "system"@en, "sistema"@es.
#+END_SRC

The two new classes that we use are defined in the MS ontology:
#+BEGIN_SRC Turtle
ms: a owl:Ontology;
  rdfs:label "Multisensor ontology";
  owl:versionInfo "1.0".

ms:GenericConcept a rdfs:Class;
  rdfs:subClassOf skos:Concept;
  rdfs:label "GenericConcept";
  rdfs:comment "Concept that doesn't belong to a specific domain";
  rdfs:isDefinedBy ms: .

ms:SpecificConcept a rdfs:Class;
  rdfs:subClassOf skos:Concept;
  rdfs:label "SpecificConcept";
  rdfs:comment "Concept from the specific Multisensor domain (determined by statistical analysis over the Multisensor corpus)";
  rdfs:isDefinedBy ms: .
#+END_SRC

* Multimedia Annotation
Multisensor includes 2 multimedia services that need to be integrated in RDF:
1. Automatic Speech Recognition (ASR) that provides raw text extracted from the video; followed by concept extraction.
2. Concept and Event Detection that provides a list of the concepts appearing in images/videos, with the degree of confidence.
This information should be useful for multimedia search. Then, we should be able to search for concepts that were detected in images, videos, and/or audio (speech recognition)

The basic NIF representation is like this:
- SIMMO
  - referenceContext
    - Sentences
      - Words/Phrases
        - taIdentRef = list of recognized Concepts / Named Entities 

We extend it for multimedia content as follows:
- SIMMO
  - hasPart StillImage = list of images present in the article
    - Annotation = list of Concepts/Events detected per image, with confidence score
  - hasPart MovingImage = list of videos present in the article
    - Annotation = list of 3..5 most confident Concepts/Events detected in the video, with confidence score
    - hasCaption = text extracted by Automatic Speech recognition
      - taIdentRef = list of recognized Concepts / Named Entities 
    - hasPart StillImage = list of some frames (images) extracted by CED
      - Annotation = list of Concepts/Events detected per image, with confidence score

*IMPORTANT: all puml triples are just for making the diagrams below and should not be emitted*

** Automatic Speech Recognition
The audio track of videos embedded in articles (SIMMOs) is passed through Automatic Speech Recognition (ASR).
This results in two products:
- Plain text *Transcript* that is passed through text analysis (NER and other NIF annotations).
  The transcript is analyzed same as the main article text. So it has similar structure to the SIMMO, with the following differences
  - The transcript doesn't have sentence boundaries thus no NIF sentence structure.
  - The transcript doesn't have context properties such as author, publication date, etc
  - The transcript is subsidiary to the article, following this nesting structure:
    - *Article* -dct:hasPart-> *Video* -ms:hasCaption-> *Caption* <-nif:sourceUrl- *Transcript*
    - Note: I considered inserting Video - *Audio* - Caption
      but decided against it since we don't have any statements about the Audio
- Structured *Captions* in [[https://w3c.github.io/webvtt/][WebVTT: The Web Video Text Tracks]] format (MIME type "text/vtt").
  The Caption file is not stored in RDF, only a link to it is in RDF

[[./img/NIF-ASR.ttl]] \\
[[./img/NIF-ASR.png]]

Notes:
- Assume that http://blog.hgtv.com/terror/2014/09/08/video is he 0th video in http://blog.hgtv.com/terror/2014/09/08/article
- Both the article and video mention "Germany" which is recognized as a named entity.
  This is just for the sake of illustration and comparison, and we don't show any other NIF statements
- I assume the video is accessed from the source URL and not copied to an MS server (that assumption is probably wrong).
  We make statements against the video URL, rather than making a MS URL (same as for Images).
  If copied to an MS server, it's better to make statements against that URL
- I assume the Caption is stored on a MS server in the indicated directory.
  If different, change the URL accordingly, but think about permanence
- The Transcript (bottom  nif:Context) uses the Caption as nif:sourceUrl.
- The Transcript's URL is subsidiary to (has as prefix) the SIMMO URL. Since we can't use two ~#~ in a URL, we use ~-~ before the ~transcript~ part and ~#~ after it. The number 0 is the sequential count (0th video)

*** Aside: ISOcat & GOLD
I was hoping that I can find a property to express "ASR transcript of an audio" in the ISOcat register or GOLD.
There's nothing appropriate in GOLD but I found an entry in http://www.isocat.org/rest/profile/19:
- PID: http://www.isocat.org/datcat/DC-4064
- Identifier: audioTranscription
- Definition: The conversion of the spoken word to a text format in the same language.
- Source: http://www.forensic-audio.net/spanish-transcription-vs-audio-translation.php (the source site doesn't exist anymore)
This is also available as RDF at http://www.isocat.org/datcat/DC-4064.rdf (which redirects to http://www.isocat.org/rest/dc/4064.rdf), but the info is minimal:
#+BEGIN_SRC Turtle
<http://www.isocat.org/datcat/DC-4064>
  rdfs:comment  "The conversion of the spoken word to a text format in the same language."@en ;
  rdfs:label    "audio transcription"@en .
#+END_SRC
The datahub entry for ISOcat https://datahub.io/dataset/isocat claims that
full profiles are available as RDF at https://catalog.clarin.eu/isocat/rest/profile/19.rdf, but this link is broken.
I found an (unofficial?) RDF dump of profile 5 at http://www.sfs.uni-tuebingen.de/nalida/images/isocat/profile-5-full.rdf
but not of profile 19.

What is worse, there is no property name defined (eg ~isocat:audioTranscription~), no domain and range.
We'll certainly won't use something like ~isocat:DC-4064~ to name our properties.
A disappointment.

** Basic Image Annotation
Before describing how an image in SIMMO is annotated, let's consider how to annotate (enrich) a *single* image.
Since images are not text, NIF mechanisms are completely inappropriate: there are no nif:Strings to be found in images.

Look at this image:\\
[[http://images.zeit.de/hamburg/stadtleben/2015-08/drage-vermisste/drage-vermisste-540x304.jpg][http://images.zeit.de/hamburg/stadtleben/2015-08/drage-vermisste/drage-vermisste-540x304.jpg]]

*NOTE:* It's recommended to copy the images to an internal server, to ensure that they
will be available in the future. If the above image disappears, any statements about its
URL become sort of useless.

CERTH has software that can annotate it with heuristic tags and confidence, eg like this
(many more tags are produced for this image):

#+BEGIN_SRC
Concepts3_Or_More_People # 0.731893
Amateur_Video            # 0.884379
Armed_Person             # 0.35975
#+END_SRC

We can represent this in RDF using various alternatives. The selected one is in sec [[*Representing Confidence with Stanbol FISE]].

*** Open Annotation
*(NOTE: This is the basic step. Sec [[*Representing Confidence with Stanbol FISE]] shows the full representation)*

The [[http://www.w3.org/TR/annotation-model/][Web Annotation Data Model]] (also known as Open Annotation, OA) is widely used for all
kinds of associating two or several resources: bookmarking, tagging, commenting,
annotating, transcription (associating the image of eg handwritten text with the
deciphered textual resources), compositing pieces of a manuscript (SharedCanvas), etc.

The OA ontology has gone through a huge number of revisions at various sites. To avoid confusion:
- The latest ontology is dated 2015-08-20 and is published at
  http://w3c.github.io/web-annotation/vocabulary/wd/. It's still a draft (some editorial
  text is missing), but the ontology is usable
- The master file is at https://raw.githubusercontent.com/w3c/web-annotation/gh-pages/vocabulary/oa.ttl
- The namespace URL http://www.w3.org/ns/oa serves an *obsolete* version

We represent image annotations as [[http://www.w3.org/TR/annotation-model/#semantic-tags][oa:SemanticTag]]:
- The image is the *target*, tags are (linked to) *bodies*
- The tags are expressed as ~oa:SemanticTag~. 
- OA asks us to describe the nature of the relation as a specific [[http://www.w3.org/TR/annotation-model/#motivations][oa:motivatedBy]]. In this
  case I picked *oa:tagging*.
- We state the nature of the resource as rdf:type dctype:Image, and its mime type as
  dc:format.
- We record basic creation (provenance) information.
[[./img/annot-image-oa.ttl]]\\
[[./img/annot-image-oa.png]]

Unfortunately OA has no standard way to express confidence, which is essential for this
use case. I have raised this as https://github.com/restful-open-annotation/spec/issues/3.
Above we use a custom property *ms:confidence*, and in further subsections I show other
options.

*** Representing Confidence with Stanbol FISE
Apache Stanbol defines an "enhancement structure" using the FISE ontology,
which amongst other things defines ~fise:confidence~.
We want to use [[http://stanbol.apache.org/docs/trunk/components/enhancer/enhancementstructure.html#fisetopicannotation][fise:TopicAnnotation]] that goes like this:\\
http://stanbol.apache.org/docs/trunk/components/enhancer/es_topicannotation.png

As you see, it points to ~fise:TextAnnotation~ using ~dc:relation~;
if [[http://stanbol.apache.org/docs/trunk/components/enhancer/enhancementstructure.html#overview-on-the-stanbol-enhancement-structure][you scroll to the top]], you'll see that points further to the (textual) annotated resource (~ContentItem~):
we don't want that since we have image not text. But there are
also ~fise:extracted-from~ (dashed arrows) pointing directly to the resource.
The *NIF+Stanbol* profile shows the same idea of using ~fise:extracted-from~ directly:\\
[[./20141008-Linguistic-LD/img/NIF-profiles.png]]

We bastardize the ontology a bit:
- skip ~dc:relation~, as we don't have ~fise:TextAnnotation~
- skip ~fise:entity-label~, as it just repeats skos:prefLabel of the concept
- skip ~fise:entity-type~, as it just repeats rdf:type of the concept
[[./img/annot-image-fise.ttl]]\\
[[./img/annot-image-fise.png]]

**** Removing Redundancy
- The construct of using ~skos:related~ is doubtful and [[https://lists.w3.org/Archives/Public/public-annotation/2015Sep/0184.html][will likely be removed]], but for now we'll use it
- The direct link ~fise:extracted-from~ to the image is redundant since ~oa:hasTarget~ already points there. So we can skip it

*** Representing Confidence with FAM
*(IMPORTANT: Ignore this section, it's not needed now.)*

The FusePoolP3 Annotation Model (FAM) has invesigated merging of OA, NIF and Stanbol FISE, and defines ~fam:confidence~ that we can use. Some links:
- https://github.com/fusepoolP3/overall-architecture/blob/master/wp3/fp-anno-model/fp-anno-model.md
- http://events.linuxfoundation.org/sites/events/files/slides/ApacheCon-Stanbol-FAM.pdf
- http://www.slideshare.net/linkedtv/linking-media-and-data-using-apache-marmotta-lime-workshop-keynote
- https://github.com/wikier/apache-marmotta-tutorial-iswc2014

We would use fam:TopicAnnotation: see a mapping from [[https://github.com/fusepoolP3/overall-architecture/blob/master/wp3/fp-anno-model/fp-anno-model.md#famTopicClassification_transformation][fise:TopicAnnotation to fam:TopicAnnotation]].
But because this results in an isomorphic graph structure, we don't show it here.

*** Representing Confidence with Reification
*(IMPORTANT: Ignore this section, it's not needed now.)*

A tried and true (although criticized by some) way of adding statements to relations is
[[http://patterns.dataincubator.org/book/reified-statement.html][RDF Reification]] that uses ~rdf:Statement, rdf:subject, rdf:predicate, rdf:object~ (a lot
more details in [[https://www.safaribooksonline.com/library/view/practical-rdf/0596002637/ch04s03.html][Practical RDF # Reification: The RDF Big Ugly]] at O'Reilly Safari. For
brevity we represent only one of the tags. It looks like this, but the diagram hides some
of the complexity so please see the turtle.
[[./img/annot-image-reif.ttl]]\\
[[./img/annot-image-reif.png]]

** Annotating Images
Assume that ~http://blog.hgtv.com/terror/2014/09/08/image.jpg~ is an 0th image in ~http://blog.hgtv.com/terror/2014/09/08/article~ and:
- The article mentions SWAT, which is coreferenced to ~dbr:SWAT~
- CED has recognized in the image the same ~dbr:SWAT~ with confidence 0.9
- CED has recognized a local concept ~ms-concept:Concepts3_Or_More_People~ with lower confidence 0.3
We follow the approach in sec [[*Representing Confidence with Stanbol FISE]], but remove the redundant link ~fise:entity-reference~

[[./img/SIMMO-annot-image.ttl]]\\
[[./img/SIMMO-annot-image.png]]

** Annotating Videos
CED extracts the 3..5 most confident Concepts/Events detected in a video, with confidence score. We represent this exactly the same as in the previous sec [[*Annotating Images]], just using the appropriate rdf:type (dctype:MovingImage) and dc:format ("video/mp4") for the video.

[[./img/SIMMO-annot-video.ttl]]\\
[[./img/SIMMO-annot-video.png]]

** Annotating Video Frames
To annotate a video frame, we use Web Annotation's [[https://www.w3.org/TR/annotation-model/#specific-resources][Specific Resources]] 
and a [[https://www.w3.org/TR/annotation-model/#fragment-selector][Fragment Selector]] that conforms to the [[https://www.w3.org/TR/media-frags/][Media Fragments]] specification.
Assume the same video as in the previous section, 
and that frame(s) from second 30 to second 31 are annotated. 
This corresponds to a selector ~#t=30,31~
(see [[https://www.w3.org/TR/media-frags/#naming-time][Temporal Dimension]] for more details including NPT vs SMPTE vs real-world clock). 
We show only one annotated concept for simplicity.

[[./img/SIMMO-annot-frame.ttl]]\\
[[./img/SIMMO-annot-frame.png]]

The dashed arrow ~dct:hasPart~ says that the frame (fragment) is part of the video. 
It is optional: it allows direct access to the annotated frames, but is redundant.

* TODO Translation
Use case: we have original text in DE that is machine-translated to EN, then annotated with NER and other NIF annotations.

[[http://www.slideshare.net/m1ci/nif-tutorial][FREME NIF Tutorial]]:
- slide 16 uses itsrdf:target to point to target (translated) text of a nif:String, but you make furtter statements about the translated text
- slide 18 shows an idea how to represent translated text as an independent document, but uses a made-up property itsrdf:translatedAs

[[http://www.w3.org/community/ontolex/wiki/Final_Model_Specification#Translation][The OntoLex vartrans]] module suggests 5 ways to represent translation. But all of them put us firmly in OntoLex land:
- the senses in source and target language share a reference to a shared concept
- class vartrans:Translation with properties vartrans:source and vartrans:target pointing the source and target sense
- property vartrans:translation that points from source to target sense
- property vartrans:translatableAs that points from source to target lexical entry
- class vartrans:TranslationSet that points to a number of vartrans:member vartrans:Translation instances

Another option is to use PROV:
- [[http://www.w3.org/TR/prov-o/#hadPrimarySource][prov:hadPrimarySource]] is the only property that mentions "translation"
- nif:wasConvertedFrom is a subprop of prov:wasDerivedFrom

* Multisensor Social Data
SMAP is a Multisensor module that does network analysis over social networks.
It gets some tweets about a topic (based on keywords or hashtags), and then determines the importance of various posters on these topics.
We use the [[http://rdfs.org/sioc/spec/][SIOC]] ontology to represent posters and topics, and then some custom properties:

[[./img/ontology.ttl]]
#+BEGIN_SRC Turtle :tangle ./img/ontology.ttl
ms:has_page_rank a owl:DatatypeProperty;
  rdfs:domain sioc:Role;
  rdfs:label "Has page rank"@en;
  rdfs:comment "Centrality and importance of a poster on particular topic"@en;
  rdfs:isDefinedBy ms: .
 
ms:has_reachability a owl:DatatypeProperty;
  rdfs:domain sioc:Role;
  rdfs:label "Has reachability"@en;
  rdfs:comment "Level of linking of a poster on particular topic"@en;
  rdfs:isDefinedBy ms: .

ms:has_global_influence: a owl:DatatypeProperty;
  rdfs:domain sioc:Role;
  rdfs:label "Has global influence"@en;
  rdfs:comment "Global influence of a poster on particular topic. A combination of page rank and reachability"@en;
  rdfs:isDefinedBy ms: .

#+END_SRC

** Topic Based on Single Keywords
Assume the following:
- We crawled two sets of tweets based on two *keywords*: "cars" and "RDF"
- The first guy (~valexiev1~) has posted on both topics. He knows a bit about "cars" but a lot about "RDF"
- The second guy (~johnSmith~) has posted only on the topic "cars", and he knows a lot about it

We represent it as follows:
- We use a namespace ~ms-soc~ where we put Social Network data
- We represent topics as ~sioc:Forum~, posters as ~sioc:UserAccount~, and poster on a topic as ~sioc:Role~
- We form node URLs from keywords and poster account names. If these include spaces or other bad chars, replace with "_"
- Keywords are strings, so we use dc:subject to express them

[[./img/SMAP-example.ttl]]
#+BEGIN_SRC Turtle :tangle ./img/SMAP-example.ttl
ms-soc:cars a sioc:Forum;
  sioc:has_host twitter: ;
  dc:subject "cars".

ms-soc:RDF a sioc:Forum;
  sioc:has_host twitter: ;
  dc:subject "RDF".

# The first guy has posted on both topics. He knows a bit about "cars" but a lot about "RDF"

twitter:valexiev1 a sioc:UserAccount;
  sioc:has_function ms-soc:cars_valexiev1, ms-soc:RDF_valexiev1.

ms-soc:cars_valexiev1 a sioc:Role;
  sioc:has_scope ms-soc:cars;
  ms:has_page_rank 0.75;
  ms:has_reachability 0.70;
  ms:has_global_influence 0.72.

ms-soc:RDF_valexiev1 a sioc:Role;
  sioc:has_scope ms-soc:RDF;
  ms:has_page_rank 7500.0;
  ms:has_reachability 7000.0;
  ms:has_global_influence 7200.0.

# The second guy has posted only on the "cars" topic. He knows a lot about "cars"

twitter:johnSmith a sioc:UserAccount;
  sioc:has_function ms-soc:cars_johnSmith.

ms-soc:cars_johnSmith a sioc:Role;
  sioc:has_scope ms-soc:cars;
  ms:has_page_rank 8.5;
  ms:has_reachability 8.0;
  ms:has_global_influence 8.2.
#+END_SRC

The graph allows a journalist to compare the importance of the same poster across keywords.

[[./img/SMAP-example.png]]

** Topic Based on Multiple Hashtags
Assume the following:
- We crawled one set of tweets based on multiple *hashtags*. We assume no special chars are present in the hashtags.
- We don't have the user names, only user IDs.
  Note: the user name (eg *@UNFCCC*) can be extracted from the ID (eg [[https://twitter.com/intent/user?user_id%3D17463923][user_id=17463923]])

We use the following representation
- We represent topics as ~sioc:Forum~, posters as ~sioc:UserAccount~, and poster on a topic as ~sioc:Role~ (same as before)
- We make the topic URLs by sorting and concatenating tags, separated with "." (a bit too long but works)
- We make poster on topic URLs by concatenating the tags and account user ID, separated with "_"
- Hashtags are resources (separately addressable), so we use dct:subject to express them
- We put each hashtag in a separate dct:subject. This would allow someone to analyze topic intersection
- For now we use just one named graph, with URL ~ms-soc:~

[[./img/SMAP-example2.ttl]]
#+BEGIN_SRC Turtle :tangle ./img/SMAP-example2.ttl

# topic URL made from sorted concatenated tags
ms-soc:civilengineering.dishwasher.energy_crisis.energy_policy.renewable.foodmanufacturing.homeappliances a sioc:Forum;
  sioc:has_host twitter: ;
  dct:subject twitter_tag:civilengineering, twitter_tag:dishwasher, 
    twitter_tag:energy_crisis, twitter_tag:policy_energy, twitter_tag:renewable,
    twitter_tag:foodmanufacturing, twitter_tag:homeappliances.

# poster on topic URL made from topic concatenated with user id
twitter_user:17463923 a sioc:UserAccount;
  sioc:has_function ms-soc:civilengineering.dishwasher.energy_crisis.energy_policy.renewable.foodmanufacturing.homeappliances_17463923.

ms-soc:civilengineering.dishwasher.energy_crisis.energy_policy.renewable.foodmanufacturing.homeappliances_17463923 a sioc:Role;
  sioc:has_scope ms-soc:civilengineering.dishwasher.energy_crisis.energy_policy.renewable.foodmanufacturing.homeappliances;
  ms:has_pagerank 0.0206942;
  ms:has_reachability 386.05;
  ms:has_overall_influence 0.143948.

twitter_user:243236419 a sioc:UserAccount;
  sioc:has_function ms-soc:civilengineering.dishwasher.energy_crisis.energy_policy.renewable.foodmanufacturing.homeappliances_243236419.

ms-soc:civilengineering.dishwasher.energy_crisis.energy_policy.renewable.foodmanufacturing.homeappliances_243236419 a sioc:Role;
  sioc:has_scope ms-soc:civilengineering.dishwasher.energy_crisis.energy_policy.renewable.foodmanufacturing.homeappliances;
  ms:has_pagerank 0.020222;
  ms:has_reachability 434.15;
  ms:has_overall_influence 0.143038.

##################
dct:subject a puml:InlineProperty.
#+END_SRC

[[./img/SMAP-example2.png]]

TODO: Decide whether to split into more coherent hashtag groups, and do separate analyses. Eg:
- energy_crisis.energy_policy.renewable vs
- dishwasher.homeappliances

** Tweets Related to Article
Assume we can collect tweets related to a crawled article (SIMMO):
- "Energiewende" is a major topic of SIMMO ~ms-content:939468~
- The tweet http://twitter.com/MSR_Future/status/605786079153627136 talks about *#energiewende*
We can express the tweet as sioc:Post. We'll express just basic data:
- sioc:content: tweet text
- sioc:has_creator: http://twitter.com/MSR_Future (or if we don't have access to the user name, we can use the user id just like above).
- dct:date: date posted

[[./img/SMAP-tweet.ttl]]
#+BEGIN_SRC Turtle :tangle ./img/SMAP-tweet.ttl
<http://twitter.com/MSR_Future/status/605786079153627136> a sioc:Post;
  sioc:has_creator <http://twitter.com/MSR_Future>;
  sioc:content """@UNFCCC @EnergiewendeGER
   That's great, just a shame it does not
   translate into lower CO2. #Energiewende""";
  dct:date "2015-06-02T20:20:00"^^xsd:dateTime;
  sioc:about ms-content:939468.

<http://twitter.com/MSR_Future> a sioc:UserAccount.
  
####################
<http://twitter.com/MSR_Future> a puml:Inline.
#+END_SRC

[[./img/SMAP-tweet.png]] 

Possible extensions:
- Extract the hashtags and mentions from the tweet
- If we start sourcing ~Posts~ from other places (eg Facebook), we should link the ~Post~
  and ~UserAccount~ to *twitter:* as a ~sioc:Forum~ or ~sioc:Site~.
- If we want to express more diverse relations than a general ~sioc:about~, we can use OA
  (see sec [[*Open Annotation]]) and ~oa:motivatedBy~. The SIMMO will be the *target* of annotation,
  and the tweet will be the *body*.

* Multisensor Sentiment Analysis
Multisensor uses MARL for representing sentiments, and a few more extension properties:

[[./img/ontology.ttl]]
#+BEGIN_SRC Turtle :tangle ./img/ontology.ttl
ms:negativePolarityValue a owl:DatatypeProperty;
  rdfs:domain marl:Opinion;
  rdfs:label "Most negative polarity value"@en;
  rdfs:comment "A sentence may include both negative and positive polarity words: this records the most negative polarity"@en;
  rdfs:isDefinedBy ms: .

ms:positivePolarityValue a owl:DatatypeProperty;
  rdfs:domain marl:Opinion;
  rdfs:label "Most positive polarity value"@en;
  rdfs:comment "A sentence may include both negative and positive polarity words: this records the most positive polarity"@en;
  rdfs:isDefinedBy ms: .

ms:sentimentalityValue a owl:DatatypeProperty;
  rdfs:domain marl:Opinion;
  rdfs:label "Sentimentality value"@en;
  rdfs:comment """How strong is the sentiment.
Sum of the absolute values of the most positive and most negative polarity of an opinion (i.e. the difference between them)"""@en;
  rdfs:isDefinedBy ms: .

ms:fluency a owl:DatatypeProperty;
  rdfs:domain nif:Context;
  rdfs:label "Text fluency"@en;
  rdfs:comment """How fluent is the text.
The text should build from sentence to sentence to a coherent body of information about a topic. 
Consecutive sentences should be meaningfully connected. Paragraphs should be written in a logical sequence. 
The best way to achieve fluency is to have at least one object or subject repeatedly mentioned in consecutive units of text. """@en;
  rdfs:comment "Range: 1.0 ... 5.0"@en;
  rdfs:isDefinedBy ms: .

ms:richness a owl:DatatypeProperty;
  rdfs:domain nif:Context;
  rdfs:label "Text richness"@en;
  rdfs:comment """How rich is the text. 
Is the writing style and vocabulary used rich and interesting, as opposed to plain and straightforward?"""@en;
  rdfs:comment "Range: 1.0 ... 5.0"@en;
  rdfs:isDefinedBy ms: .

ms:technicality a owl:DatatypeProperty;
  rdfs:domain nif:Context;
  rdfs:label "Text technicality"@en;
  rdfs:comment """How technical is the text. 
Are the topic and used language technical? 
Does it require effort and previous knowledge to understand the text?"""@en;
  rdfs:comment "Range: 1.0 ... 5.0"@en;
  rdfs:isDefinedBy ms: .

#+END_SRC

** Text Characteristics
Now let's define some sentiment analysis RDF data.
(Sentences and the context are already demarkated by a previous pipeline component.)

We start with some general characteristiccs of the text. 
This particular text is fluent, but is neither rich nor technical, so we set values 5, 1, 1 respectively.

[[./MS-sentiment.ttl]]
#+BEGIN_SRC Turtle :tangle ./img/MS-sentiment.ttl
@base <http://data.multisensorproject.eu/content/9e9c304>.

<#char=0,2000> a nif:Context;
  nif:isString "This is the whole text of the SIMMO.\n It should continue for 2000 chars but I'll stop here"@en;
  ms:fluency      5.0;
  ms:richness     1.0;
  ms:technicality 1.0.
#+END_SRC

** Sentiment of SIMMO and Sentence
The sentiment of the whole news item (SIMMO) is represented as follows:
#+BEGIN_SRC Turtle :tangle ./img/MS-sentiment.ttl
<#char=0,2000>
  nif:opinion <#char=0,2000-sentiment>.
<#char=100,200-sentiment>
  a marl:Opinion;
  marl:minPolarityValue    -5.0; # sentiment range: minimum
  marl:maxPolarityValue     5.0; # sentiment range: maximum
  ms:negativePolarityValue -3.5; # most negative sentiment
  ms:positivePolarityValue  2.0; # most positive sentiment
  marl:polarityValue       -1.5; # sum of the two polar opinions (what's the average sentiment)
  ms:sentimentalityValue    5.5. # difference of the two polar opinions (how strong is the sentiment)
#+END_SRC

The sentiment of a sentence is structured exactly as above. 
#+BEGIN_SRC Turtle :tangle ./img/MS-sentiment.ttl
<#char=100,200> a nif:Sentence;
  nif:referenceContext <#char=0,2000>;
  nif:opinion <#char=100,200-sentiment>.

<#char=100,200-sentiment>
  a marl:Opinion;
  marl:minPolarityValue    -5.0;
  marl:maxPolarityValue     5.0;
  ms:negativePolarityValue -3.5;
  ms:positivePolarityValue  2.0;
  marl:polarityValue       -1.5;
  ms:sentimentalityValue    5.5.
#+END_SRC

A sentence without any sentiment-bearing words still carries the range (~minPolarityValue~ and ~marl:maxPolarityValue~),
and a neutral ~sentimentalityValue~.
~negativePolarityValue~, ~ms:positivePolarityValue~ and ~marl:polarityValue~ are omitted.

#+BEGIN_SRC Turtle :tangle ./img/MS-sentiment.ttl
<#char=200,300>
  a <#char=200,300-sentiment>.
  
<#char=200,300-sentiment>
  a marl:Opinion;
  marl:minPolarityValue    -5.0;
  marl:maxPolarityValue     5.0;
  ms:sentimentalityValue    0.0.
#+END_SRC

** Sentiment About Named Entity
We can represent the sentiment about a NE as follows

[[./MS-sentiment-NE.ttl]]
#+BEGIN_SRC Turtle :tangle ./img/MS-sentiment-NE.ttl
@base <http://data.multisensorproject.eu/content/9e9c304>.

<#char=0,50> a nif:Context;
  nif:isString "Consumers are very unhappy with the new Porsche".

<#char=43,50> a nif:Word;
  nif:referenceContext <#char=0,50>;
  nif:beginOffset 43;
  nif:endOffset 50;
  nif:anchorOf "Porsche";
  nif:taIdentRef dbr:Porsche.

<#sentiment=dbr_Porsche> a marl:Opinion;
  marl:extractedFrom <#char=0,50>;
  marl:describesObject dbr:Porsche;
  marl:minPolarityValue -5;
  marl:maxPolarityValue 5;
  ms:negativePolarityValue -5;
  ms:positivePolarityValue 0;
  marl:polarityValue -5;
  ms:sentimentalityValue -5.
#+END_SRC

If we can pin-point the sentiment-bearing words (in this case "very unhappy"):
#+BEGIN_SRC Turtle :tangle ./img/MS-sentiment-NE.ttl
<#char=29,38> a nif:Word;
  nif:referenceContext <#char=0,50>;
  nif:beginOffset 29;
  nif:endOffset 38;
  nif:anchorOf "very unhappy".

<#sentiment=dbr_Porsche> 
  marl:opinionText <#char=29,38>.
#+END_SRC

* Content Similarity
The Content Alignment Pipeline (CAP) is a service that executes on KB data and finds articles that are similar or contradictory to the source article

<http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304#similarArticles>
  a oa:Annotation ;
  oa:hasTarget <http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304> ;
  oa:hasBody        
    <http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304#similarArticle-1> ,
    <http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304#similarArticle-2> ;
  oa:motivatedBy oa:tagging ;
  oa:annotatedBy <http://data.multisensorproject.eu/agent/CAPAgent> ;
  oa:annotatedAt "2016-01-11T12:00:00"^^xsd:dateTime .

<http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304#similarArticle-1>
  a oa:SemanticTag ;
  skos:related <http://data.multisensorproject.eu/content/ca34bb35770bfa55434a0689d64e1e6a60611047> ;
  fise:confidence 0.862 .

<http://data.multisensorproject.eu/content/53a0938bc4770c6ba0e7d7b9ca88a637f9e9c304#similarArticle-2>
  a oa:SemanticTag ;
  skos:related <http://data.multisensorproject.eu/content/57e07befbda355c2eca2ee521926071ee9f5c719> ;
  fise:confidence 0.795 .

<http://data.multisensorproject.eu/agent/CAPAgent>
  a prov:SoftwareAgent ;
  foaf:name "Content Alignment Pipeline v1.0" .

